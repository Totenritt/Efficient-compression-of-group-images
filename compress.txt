Usage:
  "kdu_compress ...
   -i <file 1>[*<copies>@<size>],...  {see also `-fprec' & `-icrop'}
       One or more input files. If multiple files are provided, they must be
       separated by commas. Any spaces will be treated as part of the file
       name.  If any filename contains the optional "*<copies>@<size>" suffix,
       that file actually contributes <copies> inputs, where the k'th copy
       starts (k-1)*<size> bytes into the file; this is most useful for raw
       files, allowing a single raw file to contribute multiple image
       components.
          Currently accepted image file formats are: TIFF (including BigTIFF),
       RAW (big-endian), RAWL (little-endian), BMP, PBM, PGM and PPM (including
       PNM files with sample precisions from 1 to 16), and PFM (i.e. floating
       point files), as determined by the file suffix.  For raw files, the
       sample bits must be in the least significant bit positions of an 8, 16,
       24 or 32 bit word, depending on the bit-depth.  Unused MSB's in each
       word are entirely disregarded.  The word organization is big-endian for
       files with the suffix ".raw", but little-endian for files with the
       suffix ".rawl" -- be careful to get this right.  Also, with raw files,
       the dimensions, precision and signed/unsigned characteristics must be
       provided separately using `Sdims' (or any other appropriate combination
       of SIZ-based canvas dimensions), `Nprecision' and `Nsigned'.
          For non-raw files, the dimension and precision information parameters
       is obtained from the file header automatically.  The `Nprecision' and
       `Nsigned' attributes are configured based on this header information. 
       In all cases, `Nprecision' and `Nsigned' are automatically transcribed
       to `Sprecision' and `Ssigned' or `Mprecision' and `Msigned' (if there is
       a Part-2 multi-component transform).   See the discussion and examples
       which appear at the end of this usage statement for more on the
       interaction between file header precision and dimensional information
       with the configuration of coding parameter attributes.
          There can be cases where you wish to compress the sample values found
       in a file, using different precision properties to those which are
       specified in the file header.  This can be arranged via the `-fprec'
       argument, which also allows you to indicate where source samples are to
       be compressed directly as floats or half-floats (potentially in a truly
       lossless manner).
          There are also cases where you wish to compress only a cropped
       portion of an input file; this is particularly useful with the `-frag'
       option.  You can arrange for such cropping to take place via the
       `-icrop' argument.
   -o <compressed file -- raw code-stream, JP2, JPH or JPX file>
       Name of file to receive the compressed code-stream.  If the file name
       has a ".jp2" or ".jph" suffix (not case sensitive), the code-stream will
       be wrapped inside a JP2/JPH file, based on whether the code-stream
       conforms to Part-1 or Part-15 (HTJ2K) of the JPEG2000 family of
       standards -- use of a ".jph" suffix also sets up the `Scap' attribute to
       include the `P15' flag so that the right type of code-stream should be
       created, unless you explicitly configure things differently.  If the
       file name has a ".jpx" or ".jpf" suffix (not case sensitive), the
       code-stream will be wrapped inside the more sophisticated JPX file
       format, with a single compositing layer.  In either case, the first 3
       source image components will be treated as sRGB colour channels (red,
       green then blue) and the remainder will be identified as auxiliary
       undefined components in the JP2/JPH/JPX file, unless there are less than
       3 colours, or a separate colour space is identified via the `-jp2_space'
       and/or `-jpx_space' arguments.
          If an input file defines a colour palette (quite common with BMP
       files), this will be preserved through the JP2/JPH/JPX file format, and
       samples will be correctly de-palettized by conformant file readers.  If
       there are fewer than 3 components available (taking any palette into
       account), the first component will be identified as a luminance
       component with the sRGB gamma and any remaining component will be
       identified as an auxiliary undefined channel.  Again, these default
       decisions may be overridden by the `-jp2_space' and/or `-jpx_space'
       arguments.
          From KDU7.2, this argument may be omitted, in which case the internal
       codestream generation machinery sees a special "structured cache"
       compressed data target that allows the data to be written out of order
       -- can be very helpful in conjunction with incremental flushing (see
       `-flush_period').  This special compressed data target actually just
       discards all generated content -- i.e., it currently exists only for
       experimental purposes -- but you may derive your own structured cache
       targets that write the content to a structured database, for example, as
       opposed to a linear file.
   -fprec <comp-0 precision>[L|M|F<E>][,<comp-1 precision> ...]
       You can use this argument to adjust the way in which sample data
       precision is interpreted for the image components found in the input
       files.  The argument takes a comma-separated list of precision
       specifiers, each of which consists of a non-negative integer, followed
       by an optional suffix of `L', `M' or `F', the latter being followed by a
       positive integer exponent precision E.  Precision specifiers correspond
       to consecutive image components, with the last specifier being
       replicated as necessary to provide specifications for all components. 
       The integer part P of the specifier, identifies the precision that is
       recorded in the header of the generated codestream.  That is, P is used
       to set the `Nprecision' attribute.  Source image samples are converted,
       if necessary, to P-bit integers which are then compressed.  To apply
       precision forcing only to a limited set of components, supply a forced
       precision of 0 for the others.
         The optional suffix L, M or F<E> determines how any precision forcing
       conversion is performed.  An `M' means that the precision forcing
       algorithm scales the data by a power of 2 so that the most significant
       bit in the original sample values aligns with the most significant bit
       of the P-bit integer that is compressed.  The L suffix means that the
       least significant bits are aligned (no scaling) -- this is also the
       default.
         The F<E> suffix means that sample values are converted to a P-bit
       floating point representation involving a leading sign bit, followed by
       E exponent bits and then P-E-1 mantissa bits.  The bits of this
       representation are then re-interpreted as P-bit integers.  Note that the
       E-bit exponent represents the true (signed) exponent, offset by
       2^{E-1}-1 so as to leave an unsigned E-bit integer, with 0 corresponding
       to denormalized numbers.  The most interesting examples of the F<E>
       option are "32F8", which corresponds to IEEE single-precision floating
       point values, and "16F5", corresponding to OpenGL half-float values. 
       However, plenty of other interesting values are readily synthesized: for
       example, "16F8" is equivalent to the 16 MSB's of an IEEE
       single-precision float, obtained by dropping the least significant 16
       mantissa bits.
         TIFF and PFM files can hold data that already has a floating-point
       representation.  Normally, these floating-point samples would be
       converted to an integer representation, but an `-fprec' specifier with
       the F<E> suffix allows the samples to be left as floats and just
       re-interpreted as P-bit integers for compression.  Most image files
       supply integer-valued samples that must be converted to floats before
       their bits can be re-interpreted as P-bit integers in the presence of an
       F<E> suffixed `-fprec' specifier.  Where this happens, N-bit original
       samples are divided by 2^N-1 if unsigned or 2^{N-1}-1 if signed, in
       order to obtain floating point values whose range is from 0.0 to 1.0  or
       (approximately) -1.0 to (exactly) 1.0, respectively.
         For raw input files, the number of bits in each original input sample
       is determined from the `Nprecision' attribute, while their
       signed/unsigned nature is determined from `Nsigned'.  The presence of
       the `-fprec' option, however, generally causes the supplied `Nprecision'
       values to be overwritten.  Raw input files with `Nprecision'=N are
       considered to hold N-bit integers, except where the F<E> suffix is
       supplied to `-fprec', in which case the original raw file samples are
       considered to be N-bit floating point values, with the same number of
       exponent bits E as the P-bit floating point values that are produced by
       precision forcing.  Thus, for example, if the `Nprecision' attribute
       holds 32 on entry and `-fprec' specifies "24F8", the input samples are
       regarded as 32-bit floats with an 8-bit exponent and 23-bit mantissa
       (standard IEEE floats) and precision forcing drops the least significant
       8 mantissa bits.
         Where an F<E> suffix is used for one or more `-fprec' precision
       forcing specifiers, two additional steps are automatically taken by the
       "kdu_compress" demo app.  First, the corresponding image components are
       automatically assigned an `NLType' attribute value of SMAG (if the
       `Nsigned' attribute is true) or UMAG (if the `Nsigned' attribute is
       false).  This introduces a sign-magnitude to two's-complement conversion
       non-linear point transform that results in efficient compression of
       floating point data.  Second, if the compressed output is written to a
       JPX file, a "Pixel Format" box is written to that file which records the
       floating point interpretation of the sample values, along with the
       mantissa precision m.  The interpretation of F<E> precision forcing
       specifiers here is intended to be identical to that of the
       floating-point pixel format specifiers in IS15444-2/AMD3.
   -icrop {<off_y>,<off_x>,<height>,<width>},...
       This argument provides a means to effectively crop the input files
       supplied by `-i' -- essentially, the input file reading code limits its
       access to just the cropped region and adjusts the dimensions reported
       for the input file(s) accordingly.  This option is especially useful
       when combined with the fragmented compression option offered by `-frag'.
       For example, you could invoke "kdu_compress" 40 times to compress a
       200GB input file in 5GB fragments, each corresponding to large tile (for
       example), simply by supplying the relevant tile indices to `-frag' and
       the corresponding tile regions to `-icrop'.  The argument takes one or
       more sets of 4 cropping parameters, each of which is enclosed in curly
       braces (remember to escape the braces in unix shells).  The first set of
       cropping parameters applies to the first file supplied via `-i'.  The
       second set of cropping parameters applies to the second input file, and
       so forth, with the final set of cropping parameters applying to any
       remaining input files.  You should note that individual readers for each
       file format may or may not support cropping -- if not supported you will
       receive an appropriate error message.  Certainly, cropping is supported
       for at least some TIFF files.
   -rgb_to_420 -- do in-line conversion of imagery to 4:2:0 YCbCr.
       This option causes the first three input image planes to be
       automatically converted from an assumed RGB space to a YCbCr
       representation with chrominance sub-sampled by 2 in each direction.  To
       be clear, the sub-sampled chrominance components are formed by box-car
       averaging of 2x2 blocks of Cb and Cr channel data after conversion,
       which is the most common and simple method, but certainly not optimal. 
       Accordingly, the "CRGoffset" coding parameter attribute is automatically
       configured to record the fact that the chrominance samples are located
       at the mid-point of each 2x2 block of luminance samples.  For
       simplicity, the input image planes are required to have even dimensions
       and compression is required to be irreversible when this option is
       selected.  If you want lossless conversion of YCbCr content, with or
       without sub-sampling, it makes sense to provide the data explicitly in
       that format so that you have full control of what it is that is being
       losslessly coded.
   -frag <tidx_y>,<tidx_x>,<thigh>,<twide>
       Use this argument to compress only a fragment of the final codestream. 
       The four parameters identify the tiles which belong to the current
       fragment.  Specifically, <tidx_y> is the vertical tile index of the
       first tile in the new fragment, measured relative to the first tile in
       the image.  That is, <tidx_y> is the number of tile rows above the
       current fragment.  Similarly, <tidx_x> is the number of tile columns to
       the left of the fragment, while <thigh> and <twide> are the number of
       tile rows and number of tile columns in the fragment.  The first
       fragment must have <tidx_x>=0 and <tidx_y>=0.  The main codestream
       header, plus any JP2/JPH/JPX header information will be written only in
       the first fragment.  Subsequent fragments cannot alter this header
       information, so if any coding parameters need to differ between
       fragments, this must be done by specifying tile-based overrides, such as
       "Clevels:T1=7", that refer to the tiles being compressed in the
       fragment.  The program leaves behind some additional information in the
       output file, after a temporary EOC marker, which can be recovered when
       the next fragment is compressed.  This information identifies the total
       number of tiles which have been compressed in all previous fragments,
       and the total number of bytes associated with these previous fragments. 
       Together, this information is used to determine whether or not this is
       the last fragment, and where any TLM information must be written.  If
       this argument is present, the dimensions of the entire image must be
       explicitly identified via the `Sdims' attribute and/or the `Ssize' and
       `Sorigin' attributes.  Also, you must supply the tiling attributes via
       `Stiles' and (optionally) `Stile_origin'.  The input image(s) supplied
       via `-i' describe only the fragment being compressed, not the entire
       image.  It is worth noting that TLM (tile-part-length) marker segments
       can be requested by defining `ORGgen_tlm', and that this funcionality
       works even when the image is being compressed in fragments.  Note
       finally, that the `-icrop' argument allows you to effectively crop input
       files to just the fragment you are interested in compressing -- saves
       you having to split large input files up into fragments first.
   -roi {<top>,<left>},{<height>,<width>} | <PGM image>,<threshold>
       Establish a region of interest (foreground) to be coded more precisely
       and/or earlier in the progression than the rest of the image
       (background).  This argument has no effect unless the "Rshift" attribute
       is also set.  The "Rlevels" attribute may also be used to control the
       number of DWT levels which will be affected by the ROI information.
          The single parameter supplied with this argument may take one of two
       forms.  The first form provides a simple rectangular region of interest,
       specified in terms of its upper left hand corner coordinates
       (comma-separated and enclosed in curly braces) and its dimensions (also
       comma-separated and enclosed in braces).  All coordinates and dimensions
       are expressed relative to the origin and dimensions of the high
       resolution grid (or canvas), using real numbers in the range 0 to 1. If
       the original image is to be rotated during compression (see `-rotate'),
       the coordinates supplied here are to be interpreted with respect to the
       orientation of the image being compressed.
          The second form for the single parameter string supplied with the
       `-roi' argument involves a named (PGM) image file, separated by a comma
       from an ensuing real-valued threshold in the range 0 to 1.  In this
       case, the image is scaled (interpolated) to fill the region occupied by
       each image component.  Pixel values whose relative amplitude exceeds the
       threshold identify the foreground region.
   -rate -|<bits/pel>,<bits/pel>,...
       One or more bit-rates, expressed in terms of the ratio between the total
       number of compressed bits (including headers) and the product of the
       largest horizontal and  vertical image component dimensions.  A dash,
       "-", may be used in place of the first bit-rate in the list to indicate
       that the final quality layer should include all compressed bits. 
       Specifying a very large rate target is fundamentally different to using
       the dash, "-", because the former approach may cause the incremental
       rate allocator to discard terminal coding passes which do not lie on the
       rate-distortion convex hull.  This means that reversible compression
       might not yield a truly lossless representation if you specify `-rate'
       without a dash for the first rate target, no matter how large the
       largest rate target is.
          If "Clayers" is not used, the number of layers is set to the number
       of rates specified here. If "Clayers" is used to specify an actual
       number of quality layers, one of the following must be true: 1) the
       number of rates specified here is identical to the specified number of
       layers; or 2) one, two or no rates are specified using this argument. 
       When two rates are specified, the number of layers must be 2 or more and
       intervening layers will be assigned roughly logarithmically spaced
       bit-rates. When only one rate is specified, an internal heuristic
       determines a lower bound and logarithmically spaces the layer rates over
       the range.
          Note that from KDU7.2, the algorithm used to generate intermediate
       quality layers (as well as the lower bound, if not specified) has
       changed.  The new algoirthm introduces a constant separation between
       logarithmically expressed distortion-length slope thresholds for the
       layers.  This is every bit as useful but much more efficient than the
       algorithm employed by previous versions of Kakadu.
          Note also that the default `-tolerance' value is 2%, meaning that the
       actual bit-rate(s) may be as much as 2% smaller than the specified
       target(s).  Specify `-tolerance 0' if you want the most precise rate
       control.
          If this argument is used together with `-slope', and the values
       supplied to `-slope' are non-zero (i.e., slope would also limit the
       amount of compressed data generated), the interpretation of the layer
       bit-rates supplied via this argument is altered such that they represent
       preferred lower bounds on the quality layer bit-rates that will be taken
       into account in the event that the distortion-length slopes specified
       directly via the `-slopes' argument lead to the generation of too little
       content (i.e., if the source image turns out to be unexpectedly
       compressible).  Note carefully, though, that the ability of the system
       to respect any such lower bounds is limited by the number of bits
       generated by block encoding, which may depend upon quantization
       parameters as well as the use of slope thresholds during block encoding;
       to avoid such limitations, you may wish to consider adjusting the
       `Qstep' attribute and/or specifying the `-full' option.
   -slope <layer slope>,<layer slope>,...
       If present, this argument provides rate control information directly in
       terms of distortion-length slope values.  In most cases, you would not
       also supply the `-rates' argument; however, if you choose to do so, the
       values supplied via the `-rates' argument will be re-interpreted as
       lower bounds (as opposed to upper bounds) on the quality layer
       bit-rates, to be considered if the distortion-length slopes supplied
       here lead to unexpectedly small amounts of compressed data.  See the
       description of `-rate' for a more comprehensive explanation of the
       interaction between `-rate' and `-slope'; the remainder of this
       description, however, assumes that `-slope' is supplied all by itself.
          If the number of quality layers is  not specified via a `Clayers'
       argument, it will be deduced from the number of slope values.  Slopes
       are inversely related to bit-rate, so the slopes should decrease from
       layer to layer.  The program automatically sorts slopes into decreasing
       order so you need not worry about getting the order right.  For
       reference we note that a slope value of 0 means that all compressed bits
       will be included by the end of the relevant layer, while a slope value
       of 65535 means that no compressed bits will be included in the  layer. 
       The list of layer slope values must include at least one non-zero value.
       If fewer slopes are provided than the number of quality layers, there is
       an internal algorithm which either extrapolates or interpolates the
       values you have provided using a reasonable heuristic.  Basically, the
       heuristic starts with the assumption that 256 is an excellent amount to
       separate successive layer slopes, since it represents roughly a sqrt(2)
       change in the bit-rate ignoring header overhead for most cases.  The
       heuristic will not insert smaller slopes than the smallest one you
       supply, since that represents the maximum desired quality.  If you
       supply two slopes, which are reasonably close together, the heuristic
       will reproduce the spacing you supply with these, but if interpolating
       the largest two supplied slopes leaves a gap closer to 256, that
       approach will be adopted.
   -bstats <src file>[,<out file>]
       This option (read "background stats") is strongly recommended in
       conjunction with the "Cplex" attribute's "EST" statistical complexity
       constraint method, when there is a "-rate" target, except where a
       high-memory "Cplex-EST" configuration is used, to avoid forecasting the
       complexity of unseen subband samples -- high-memory "Cplex-EST" is
       recommended with the "Scbr" constant-bit-rate (low latency) flushing
       model, but not for image-wide rate control.  Note that the "Cplex-EST"
       algorithm itself is strongly recommended for maximum throughput when the
       HT (high-throughput) block coding algorithm ("Cmodes=HT") is employed
       with only one quality layer.
          The "-bstats" option instantiates machinery for managing a
       "background" statistical model for scene complexity, where the <src
       file> string supplies the path to a file with pre-existing statistics
       and the (optional) <out file> string supplies the path to a file to
       which collected (aggregated) statistics should be saved -- typically,
       this becomes the <src file> for future compression work.  If there is no
       existing set of statistics, but you want to generate one, use a "-" for
       the <src file>.  Statistics are stored in a human readable plain text
       format, although we do not recommend manual editing of the files.
          Complexity statistics depend upon coding parameters and the number of
       components (e.g., colour planes), but have no dependence on the target
       bit-rate; for irreversible compression (default "Creversible=no") the
       statistics are also largely independent of the bit-depth of the
       processed imagery.  We do recommend, however, that you collect
       statistics for the same type of imagery and the coding parameters that
       you intend to use the statistics with.  The statistics do not have to be
       followed closely by content being compressed -- they serve only to
       improve robustness of the "Cplex-EST" complexity control strategy, when
       used to compress imagery with deterministic complexity constraints --
       this is only important in low memory variants of the "Cplex-EST"
       algorithm.
          Supplying this argument together with a "-rate" constraint results in
       the automatic introduction of the minimum memory "Cplex={6,EST,0.25,0}"
       option, unless a "Cplex" attribute is explicitly provided.
   -full -- forces encoding and storing of all bit-planes.
       By default, the system incrementally constructs conservative estimates
       of the final rate allocation parameters and uses these to skip coding
       passes which are very likely to be discarded during rate allocation. 
       You might like to use the `-full' option if you are compressing an image
       with highly non-uniform statistics, so that rate prediction estimates
       that may truncate the amount of generated content are highly unreliable.
       You might also like to use the `-full' option if you are using the
       `-slope' and `-rate' arguments together, in which case the `-slope'
       argument provides primary control over the generation of quality layers,
       subject to lower bounds on the quality layer bit-rates that are
       specified via `-rate'.  If you do not specify `-full' in such cases, the
       smallest distortion-length slope threshold supplied via the `-slope'
       argument will be used to limit the amount of compressed data that is
       actually generated during block encoding, which will limit (but not
       nullify) the effectiveness of the lower rate bounds specified via
       `-rate'.  Note that the `-full' option does not interfere with the
       complexity control mechanism associated with the `Cplex' attribute's
       `EST' method, if it is specified.
   -periodic_trimming yes|no -- override default policy
       The system has the ability to discard compressed code-bytes which we
       know we will not be needing on a regular basis, so as to conserve
       memory.  For large images, the memory consumption might become a
       problem, especially if incremental flushing is not being used (see
       `-flush_period').  On the other hand, periodically trimming the
       compressed data that we know will ultimately not be written to the final
       codestream can require substantial memory access overheads and may also
       lock up an internal critical section for some time, which may
       potentially affect multi-threaded processing efficiency.  For these
       reasons, the default policy is to enable periodic trimming only when
       processing in the single-thread (corresponding to `-num_threads 0').
   -precise -- forces the use of 32-bit representations.
       By default, 16-bit data representations will be employed for sample data
       processing operations (colour transform and DWT) whenever the image
       component bit-depth is sufficiently small.
   -tolerance <percent tolerance on layer sizes given using `-rate'>
       This argument affects the behaviour of the `-rate' argument slightly,
       providing a tolerance specification on the achievement of the cumulative
       layer bit-rates given by that argument.  It has no effect if layer
       construction is controlled using the `-slope' argument.  The rate
       allocation algorithm will attempt to find a distortion-length slope such
       that the bit-rate, R_L, associated with layer L is in the range
       T_L*(1-tolerance/100) <= R_L <= T_L, where T_L is the target bit-rate,
       which is the difference between the cumulative bit-rate at layer L and
       the cumulative bit-rate at layer L-1, as specified in the `-rate' list. 
       Note that the tolerance is given as a percentage, that it affects only
       the lower bound, not the upper bound on the bit-rate, and that the
       default tolerance is 2%.  For the most precise rate control, you should
       provide an explicit `-tolerance' value of 0.  The lower bound associated
       with the rate tolerance might not be achieved if there is insufficient
       coded data (after quantization) available for rate control -- in that
       case, you may need to reduce the quantization step sizes employed, which
       is most easily done using the `Qstep' attribute.
   -trim_to_rate -- use rate budget as fully as possible
       This argument is relevant only when `-rate' is used for rate control, in
       place of `-slope', and only when `-tolerance' is not set to 0.  Under
       these circumstances, the default behaviour is to find distortion-length
       slope thresholds that achieve the `-rate' objectives (to within the
       specified `-tolerance') and to truncate encoded block bit-streams based
       on these thresholds.  If this argument is specified, however, one
       additional coding pass may be included from some code-blocks in the
       final quality layer, so as to use up as much of the available `-rate'
       budget as possible, for each individual frame.  If `-tolerance' is set
       to 0, the default behaviour is modified so that trimming occurs
       automatically.
   -flush_period <incremental flush period, measured in image lines>
       By default, the system waits until all compressed data has been
       generated, by applying colour transforms, wavelet transforms and block
       encoding processes to the entire image, before any of this compressed
       data is actually written to the output file.  The present argument may
       be used to request incremental flushing, where the compressed data is
       periodically flushed to the output file, thereby avoiding the need for
       internal buffering of the entire compressed image.  The agument takes a
       single parameter, identifying the minimum number of image lines which
       should be processed before each attempt to flush new code-stream data. 
       The actual period may be larger, if insufficient data has been generated
       to progress the code-stream.
          Incremental flushing may be used with either `-slope' controlled
       quality layers, or `-rate' driven quality layers; however, with
       rate-driven quality layers you should be particularly careful to keep
       the flushing period large enough to give the rate control algorithm a
       decent amount of compressed data to perform effective rate control. 
       Generally a period of at least 1000 image lines should be used for rate
       driven flushing.  An important exception to this, however, is when the
       `Scbr' attribute is used to enforce the use of a low-latency
       rate-control procedure tailored for constant bit-rate (or fixed maximum
       bit-rate) communication channels -- in that case, it is reasonable to
       make the flush period any multiple of the CBR "flush-set" size, which is
       explained with the `Scbr' option and reported on the command-line.
          Except when writing to a structured cache (see below), incremental
       flushing is possible only on tile boundaries or when the packet
       progression sequence is spatially progressive (PCRL), with sufficiently
       small precincts.  The vertical dimension of precincts in the lowest
       resolution levels must be especially tightly controlled, particularly if
       you have a large number of DWT levels.  As an example, with `Clevels=6',
       the following precinct dimensions would be a good choice for use with
       32x32 code-blocks:
       `Cprecincts={256,256},{128,128},{64,64},{32,64},{16,64},{8,64},{4,64}'.
          From KDU7.2, the underlying `kdu_compressed_target' base class
       supports extension classes that offer the ability to receive content in
       the form of structured elements (main header, tile headers and
       precincts) in an arbitrary order.  We refer to these as "structured
       cache" targets, because they must either cache the elements prior to
       rewriting them as a conventional JPEG2000 codestream in linear order, or
       else they will be used directly as caching `kdu_compressed_source'
       objects (these have been well defined for a long time) for injestion by
       Kakadu's decompression and rendering machinery.  This demo app
       instantiates a special "null" target if no output file is supplied
       (i.e., no "-o" argument), and this target is of the structured cache
       variety, even though it does not actually cache anything.  The main
       purpose of this is to allow you to see how much more flexible and
       efficient the incremental flushing paradigm can be with a structured
       cache as the compressed data target.  In this case, you will find that
       there is no need to choose precincts with very small heights in the
       lower resolution levels; in fact, massive images can be incrementally
       flushed without any restriction on the number of DWT levels (`Clevels')
       and without any need for tiling; the packet progression order is also
       irrelevant, but we recommend that you set `Corder' equal to "RPCL" for
       very large images, in case a linear codestream is later written from the
       structured cache.  A typical configuration for precincts in this case
       would be `Cprecincts={256,256},{128,256},{64,256}', so that after the
       highest 2 resolution levels, all lower resolutions use precincts of
       height 64.  This typically works very well with a flush period of 1024,
       for example, even if `Clevels' is very large.
   -no_info -- prevents the inclusion of layer info in COM segments.
       A code-stream COM (comment) marker segment is included in the main
       header to record the distortion-length slope and the size of each
       quality layer which is generated.  If you wish to make the file as small
       as possible and are working with small images, you may wish to disable
       this feature by specifying the `-no_info' flag.
   -no_version -- prevents inclusion of a KDU version COM segment.
       A code-stream COM (comment) marker segment is automatically included by
       default, to indicate the version of Kakadu that created the codestream. 
       You can disable this behaviour with this option.
   -com <comment string>
       You can use this argument any number of times to include your own
       comments directly in the codestream, as COM marker segments.  Of course,
       the supplied comment string must appear as a single command-line
       argument, so you will need to quote any strings which contain spaces
       when you supply this argument on the command line.
   -no_weights -- target MSE minimization for colour images.
       From Kakadu version 8.0.4, this option is equivalent to specifying
       "Ctype=N", which forces all image components to be treated as
       non-visual, so that they do not receive any default subband weighting
       factors -- this is optimal from the perspective of minimizing the MSE
       (Mean Squared Error) distortion over all reconstructed image components,
       when the post-compression rate-distortion optimization algorithm is
       exercised in response to "-rate" or "-slope" constraints, or if the
       `Qweights' attribute is specified, or when `Qfactor' is used to drive
       compressed image quality -- but `Qfactor' is designed with visual
       quality in mind.
          You would typically use this option to disable the automatic
       assignment of visual component types via `Ctype' when the content being
       compressed appears to be RGB colour imagery, or when greyscale content
       is compressed using a `Qfactor'.  In brief, the automatic assignment
       policy works as follows when none of "-no_weights", "-grey_weights" or
       "-chroma_weights" is specified: 1) Content with 3 compatible components,
       where the decorrelating multi-component transform is employed, is
       assumed to be RGB content yielding Y, Cb and Cr type visual components
       upon transformation; 2) If the "-rgb_to_420" option is used, then visual
       weights are again assigned based on Y, Cb and Cr type component
       attributes after the conversion to 4:2:0; 3) If the `Qfactor' attribute
       is used with content involving less than three image components, the
       first component is automatically assigned a visual (Y=luminance) `Ctype'
       and any extra component is assigned the non-visual (N) `Ctype'. 
       Currently, colour spaces specified via "-jp2_space" or "-jpx_space" do
       not affect the automatic assignment of visual component types, which
       should in any case be done explicitly using the `Ctype' attribute.
          Note also that this option has no effect if you specify the `Ctype'
       or `Cband_weights' attributes explicitly, but a warning is generated if
       any existing attributes directly or indirectly specify visual weights.
   -grey_weights -- automatic visual weights for grey-scale data.
       From Kakadu version 8.0.4, this option is equivalent to specifying
       "Ctype=Y,N", which forces the first image component to be treated as a
       luminance component and any other components to be treated as non-visual
       (unweighted).  As with "-no_weights", the option has no effect if
       `Ctype', `Cband_weights' or `Clev_weights' attributes are already
       specified, but a warning will be issued in such cases.  It is worth
       noting that in the special case where there are less than 3 image
       component and a `Qfactor' is supplied, the "-grey_weights" behaviour is
       applied automatically.
   -chroma_weights <chroma order = 1(YCbCr), 2(YUV) or 3(unknown)>.
       From Kakadu version 8.0.4, this option is equivalent to specifying
       "Ctype=Y,Cb,Cr,N", "Ctype=Y,Cr,Cb,N" or "Ctype=Y,C,C,N", for chroma
       orders of 1, 2 and 3, respectively.  In all cases, the intent is to
       ensure that visual weighting factors are introduced automatically,
       treating the first component as luminance and the next two as
       chrominance channels, where Cb corresponds to a blue-luma colour
       difference, Cr to a red-luma colour difference, and C as an colour
       difference of unknown type; any additional channels (e.g., alpha) are
       treated as non-visual (not to be visually weighted).  It is arguably
       preferable to explicitly specify `Ctype', but the present option is
       preserved from earlier Kakadu versions for backward compatibility.  
       Like "-no_weights'" and "-grey_weights", the option has no effect if
       `Ctype', `Cband_weights' or `Clev_weights' attributes have been
       explicitly specified, but a warning will be issued in such cases.  If
       this option is not supplied, the YCbCr assignment will be applied
       automatically, if the content appears likely to correspond to RGB
       imagery, or the "-rgb_to_420" option is used, as explained with the
       "-no_weights" option.  However, for original luma-chroma source content,
       including content with sub-sampled chominance components, no default
       assignment of visual weighting factors applies, even if the "-jp2_space"
       or "-jpx_space" arguments are used to specify the colour space itself.
   -no_palette
       This argument is meaningful only when reading palettized imagery and
       compressing to a JP2/JPH/JPX file.  By default, the palette will be
       preserved in the JP2/JPH/JPX file and only the palette indices will be
       compressed.  In many cases, it may be more efficient to compress the RGB
       data as a 24-bit continuous tone image. To make sure that this happens,
       select the `-no_palette' option.
   -jp2_space <sLUM|sRGB|sYCC|iccLUM|iccRGB>[,<parameters>]
       You may use this to explicitly specify a JP2 compatible colour space
       description to be included in a JP2/JPH/JPX file.  If the colour space
       is `sLUM' or `iccLUM', only one colour channel will be defined, even if
       the codestream contains 3 or more components.  The argument is illegal
       except when the output file has the ".jp2", ".jpx" or ".jpf" suffix, as
       explained above.  Note that for JPX files (those having a ".jpx" or
       ".jpf" suffix), the `-jpx_space' argument may be supplied as an
       alternative or in addition to this argument to provide richer colour
       descriptions or even multiple colour descriptions.  The pesent argument
       must be followed by a single string consisting of one of 6 colour space
       names, possibly followed by a comma-separated list of parameters.
          If the space is "iccLUM", two parameters must follow, `gamma' and
       `beta', which identify the tone reproduction curve.  As examples, the
       sRGB space has gamma=2.4 and beta=0.055, while NTSC RGB has gammma=2.2
       and beta=0.099.  A pure power law has beta=0, but is not recommended due
       to the ill-conditioned nature of the resulting function around 0.
          If the space is "iccRGB", 9 parameters must follow in the comma
       separated list.  The first two of these are the gamma and beta values,
       as above.  The next 2 parameters hold the X and Y chromaticity
       coordinates of the first (typically red) primary colour.  Similarly, the
       next 4 parameters hold the X,Y coordinates of the second (typically
       green) and third (typically blue) primary colour.  The final parameter
       must be one of the two strings "D50" or "D65", identifying the
       illuminant.  The present function assumes that equal amounts of all 3
       primary colours produce the neutral (white) associated with this
       illuminant.
   -jpx_space <enumerated colour space>,[<prec>,<approx>]
       This argument may be used only when writing JPX files (those with a
       ".jpx" or ".jpf" suffix).  Although JPX files may contain arbitrary ICC
       profiles, we do not provide the capability to include these from the
       command line.  Instead, we list here only the enumerated colour space
       options defined by JPX.  If `-jp2_space' is also supplied, multiple
       colour descriptions will be written, with the JP2 compatible description
       appearing first.  If the `prec' and `approx' parameters are omitted from
       the parameter list, they default to 0.  Otherwise, the supplied
       precedence must lie in the range -128 to +127 and the supplied
       approximation level must lie in the range 0 to 4.  The following
       enumerated colour space names are recognized:
           `bilevel1', `bilevel2', `YCbCr1', `YCbCr2', `YCbCr3', `PhotoYCC',
           `CMY', `CMYK', `YCCK', `CIELab', `CIEJab', `sLUM', `sRGB', `sYCC',
           `esRGB', `esYCC', `ROMMRGB', `YPbPr60',  `YPbPr50'.
   -jph_non_space <hex4-key>[,<hex4-key>[,...]]
       You can use this argument to specify one or more "non-colour" channels
       -- i.e., channels that are not associated with any colour space.  Each
       such channel has an 16-bit assocation key that is specified here by 4
       hex characters (upper or lower case), the <hex4-key>.  There is one
       <hex4-key> for each non-colour channel.  The term "non-colour" only
       means that these channels do not use a defined colour space; they may,
       however, represent colour or non-colour values.  Typical examples
       include raw sensor data from a camera, IR, depth, elevation or other
       scientific data.  Multiple non-colour channels can be assigned the same
       <hex4-key>, meaning that they describe the same type of content -- an
       example would be the 2 green channels from Bayer CFA sensor data.  It is
       possible to specify both colour and non-colour channels, by also
       including an explicit "-jp2_space" or "-jpx_space" argument.  In this
       case, the colour space components come first, followed by the non-colour
       components.
   -jp2_alpha -- treat first unbound component as alpha
       Use this argument if you want one of the image components to be treated
       as an alpha channel for the pixels whose colour is represented by the
       preceding components.  If the colour space is grey-scale (see
       `-jp2_space'), component 0 represents the intensity and component 1
       represents alpha.  More generally, if the colour space involves C colour
       channels and NC non-colour channels (see `-jph_non_space'), the first
       C+NC components represent colour and non-colour channels, and the next
       one represents alpha.
   -jp2_aspect <aspect ratio of high-res canvas grid>
       Identifies the aspect ratio to be used by a conformant JP2/JPH/JPX
       reader when rendering the decompressed image to a display, printer or
       other output device.  The aspect ratio identifies ratio formed by
       dividing the vertical grid spacing by the horizontal grid spacing, where
       the relevant grid is that of the high resolution canvas.  Sub-sampling
       factors determine the number of high resolution canvas grid points
       occupied by any given image component sample in each direction.  By
       default conformant JP2/JPH/JPX readers are expected to assume a 1:1
       aspect ratio on the high resolution canvas, so that the use of
       non-identical sub-sampling factors for an image component implies a
       required aspect ratio conversion after decompression.
   -jpx_layers [*|<num layers>]
       This argument provides a simple mechanism for generating JPX files which
       contain multiple compositing layers, each drawing their information from
       a single codestream.  A common application for this argument would be to
       assign each image component (each slice) in a compressed medical volume
       to a separate compositing layer.  This allows efficient interactive
       delivery of the compressed volume over JPIP, even where a
       multi-component transform has been used to exploit redundancy between
       components.  To create richer JPX files, involving any number of
       codestreams and the possibility of mixing components from different
       codestreams in a single compositing layer, use the "kdu_merge" utility
       to combine sources and redefine the layering, colour space and other
       metadata.  The present argument takes a single parameter, which either
       specifies the number of layers L >= 1 to be generated, or specifies the
       wildcard `*', which means that as many layers should be generated as
       possible.  The number of image components, C, used by each compositing
       layer is determined by the colour space supplied to `-jp2_space' or
       `-jpx_space', possibly supplemented by an alpha component if
       `-jp2_alpha' is specified.  In the absence of a supplied colour space,
       the colour space is set to sLUM (if the number of components is less
       than 3) or sRGB, for which C=1 and C=3, respectively.  The created JPX
       compositing layers consume components in order, C at a time, so that
       there must be at least C*L image components available -- these are the
       output image components produced at the output of any multi-component
       transform during decompression (given by the `Mcomponents' attribute). 
       If the wildcard is given, the value of L is set as large as possible so
       that C*L does not exceed the number of available components.
   -jp2_box <file 1>[,<file 2>[,...]]
       This argument provides a crude method for allowing extra boxes to be
       inserted into a JP2 or JPX file.  The extra boxes are written after the
       main file header boxes, but before the contiguous code-stream box.  The
       argument takes a comma-separated list of file names, without any
       intervening space.  Each file represents a single top-level box, whose
       box-type is found in the first 4 characters of the file, and whose
       contents start immediately after the first new-line character and
       continue until the end of the file.  The first line of the file (the one
       containing the box-type characters and preceding the box contents)
       should not be more than 128 characters long.  Each file may contain
       arbitrary binary or ASCII data, but is always opened as binary.
   -rotate <degrees>
       Rotate source image prior to compression. Must be multiple of 90
       degrees.
   -flip -- horizontally flip the image
       Horizontally flips the source image prior to compression.  If "-rotate"
       is also provided, horizontal flipping is notionally performed first,
       followed by rotation.
   Sprofile={ENUM<PART1,PART2,OTHER,PART1_UNREC,PART2_UNREC,OTHER_UNREC,PROFILE
   0,PROFILE1,CINEMA2K,CINEMA4K,BROADCAST,CINEMA2S,CINEMA4S,CINEMASS,IMF>}
       This attribute is a label (or category) for any restricted profile to
       which the codestream conforms, as identified uniquely via `Sprf_num'. 
       In some cases, such as the CINEMA... profiles, this label uniquely
       identifies the profile.  In other cases, the label is further qualified
       by level/sub-level information found in attributes such as `Sbroadcast'
       or `Simf'.  In every case, though, the profile is uniquely identified by
       `Sprf_num'.
          PART1, PART2 and OTHER are all pseudo-profiles, in that they
       correspond to `Sprf_num'=0, meaning that the codestream does not signal
       any profile information.  PART1 identifies a Part-1 conforming
       codestream that is otherwise unconstrained.  PART2 means that Part-2
       technologies are used, possibly together with other parts of the JPEG
       2000 family of standards, but no profile is signalled.  OTHER means that
       technologies from other parts of the JPEG 2000 family are used, not
       including Part-2.  The use of technologies from other parts can be
       discovered via the `Scap' attribute.
          PART1_UNREC, PART2_UNREC and OTHER_UNREC have similar meanings to
       PART1, PART2 and OTHER, except that a profile is signalled, as found in
       `Sprf_num', but the profile number is not recognized by Kakadu.
          PROFILE0, PROFILE1, CINEMA2K, CINEMA4K, CINEMA2S, CINEMA4S, CINEMASS,
       BROADCAST and IMF are all restricted Part-1 profiles.  PROFILE0' is the
       most restrictive profile for Part-1 conforming codestreams; this and
       PROFILE1 are not widely used.  CINEMA2K and CINEMA4K correspond to
       profile restrictions for Digital Cinema with only 1 quality layer, while
       CINEMA2S and CINEMA4S correspond to scalable extensions allowing 2
       quality layers, and CINEMASS is a "long term storage" digital cinema
       profile, that supports dimensions up to 16384 x 8640 and 5 quality
       layers.
          BROADCAST identifies profile restrictions for broadcast applications
       that are ellaborated further by the `Sbroadcast' attribute.  IMF is used
       for IMF (Interoperable Master Format) profiles, which are characterized
       by main- and sub-levels, reversibility (or lack thereof) and three
       different maximum frame sizes (2K, 4K and 8K), as identified via the
       `Simf' attribute.
          When generating a codestream with an IMF or BROADCAST profile, it is
       sufficient to provide just the `Simf' or `Sbroadcast' attribute
       parameters, leaving Kakadu to set the `Sprofile' and `Sprf_num' values. 
       The PART1, PART2 and OTHER values are also set automatically by the
       system if it determines that a codestream without any other profile
       information conforms to Part-1, or uses Part-2 technology or technology
       from other parts of the JPEG 2000 family.
          The system does perform some extensive checks for compliance with the
       profiles when they are used.  This is done with the aid of the
       `Sallowed', `Srequired', `Smodes_allowed', `Smodes_required' and
       `Slevels_allowed' pseudo-attributes that are derived from profiles but
       can be set externally (using a profile that is not recorded in the
       codestream).  The system also makes efforts to set default values for
       other attributes in order to ensure profile compliance.  However, cinema
       profiles in particular, generally require `Creslengths' (and possibly
       `Cagglengths') attributes to be configured explicitly in order to ensure
       that compressed data sizes match application-dependent constraints.
   Scpf_profile={ENUM<PART1,PART1_UNREC,PROFILE0,PROFILE1,CINEMA2K,CINEMA4K,BRO
   ADCAST,CINEMA2S,CINEMA4S,CINEMASS,IMF>}
       Like `Sprofile', this attribute holds a label (or category) that is
       derived from an actual profile number -- in this case, the number found
       in `Scpf_num', which represents a Part-1 corresponding profile for a
       Part-15 codestream.  Only Part-1 profile labels can be found here, but
       the values are otherwise the same as those available to `Sprofile'.  As
       with `Sprofile', if the value found here is IMF or BROADCAST, then
       additional level/sub-level information for the corresponding profile is
       provided via `Simf' or `Sbroadcast', as appropriate.
          This attribute is usually set automatically by the system, but you
       can directly install a corresponding profile for a Part-15 codestream if
       you believe it to be appropriate -- the system will check the profile's
       validity.  For example, you could set `Scpf_profile' to IMF and set
       `Simf' to indicate the relevant level/sub-level information, after which
       the system will install the correct `Scpf_num' value and check
       compliance of the codestream.  It must, however, be a Part-15 codestream
       -- see the `Scap' attribute.
   Sprf_num={<int>}
       This attribute may be extended in the future to allow representation of
       values larger than a 32-bit integer, but for the moment 32 bits are
       quite sufficient.  The value recorded here appears either in the `Rsiz'
       field of the `SIZ' marker segment or in a seprate `PRF' marker segment. 
       A non-zero value corresponds to a unique profile.  The system will
       attempt to infer a label for the profile, storing it in `Sprofile',
       placing any level/sub-level aspects of the profile into other parameter
       attributes, such as `Simf' and `Sbroadcast'.  Alternatively, starting
       from `Sprofile', `Simf' or `Sbroadcast', the system will deduce the
       `Sprf_num' value automatically.  During codestream generation, it is
       rare to specify `Sprf_num' directly yourself.
   Scpf_num={<int>}
       Similar to `Sprf_num', but this one corresponds to the `Scpf_profile'
       label, along with any level/sub-level information that might be found in
       attributes such as `Simf' and `Sbroadcast'.  The information here is
       recorded in a CPF (corresponding profile) marker segment, if non-zero. 
       A non-zero value is only permitted for Part-15 codestreams -- see `Scap'
       for more on how membership of different parts of the JPEG 2000 family is
       signalled.  If a Part-15 codestream has a non-zero corresponding profile
       number `Scpf_num' then it belongs to a conformance class whose members
       all arise from the transcoding of Part-1 codestreams with the
       corresponding `Sprf_num' value, making no changes other than those that
       relate to possible use of the Part-15 HT block coder -- `Cmodes' values
       `Cmodes_HT' and `Cmodes_HTMIX'.
          The Part-15 standard allows for the inclusion of a CPF marker segment
       that identifies a CPFnum value of 0, for which the semantics would be:
       this Part-15 codestream conforms to Part-1 apart from the (possible) use
       of the Part-15 HT block coder.  These semantics are redundant, since the
       same information is already communicated via `Scap' and `Sprofile'. 
       Nonetheless, Kakadu can preserve this zero-valued CPFnum, but it does so
       by storing the otherwise impossible value 4095 in `Scpf_num', while
       setting `Scpf_profile' to the rather uninteresting value of
       `Sprofile_PART1'.
   Sbroadcast={<int>,ENUM<single,multi>,ENUM<irrev,rev>}
       This parameter attribute provides more specific details for the
       BROADCAST profile or corresponding-profile, associated with one of the
       labels `Sprofile' = BROADCAST or `Scpf_profile' = BROADCAST.  During
       codestream generation, if `Sbroadcast' is specified, `Sprofile' will
       automatically be set to BROADCAST and `Sprf_num' will be set
       accordingly, except where `Scpf_profile' is already equal to BROADCAST,
       in which case the `Sbroadcast' attribute is used to determine the
       complete corresponding profile number in `Scpf_num'.
          The first field identifies the broadcast profile level, which is
       currently required to lie in the range 0 through 11.  The profile level
       identifies the maximum bit-rate (in Mbits/s meaning 10^6 bits/s) and
       sample-rate (in Msamples/s meaning 10^6 samples/s) of a compressed video
       stream, as described in Ammendment 4 to IS15444-1 and subsequently
       augmented by Ammendment 8 to IS15444-1.  Levels are as follows: 0 means
       unconstrained; 1 means 200Mbits/s,65Msamples/s; 2 means
       200Mbits/s,130Msamples/s; 3 means 200Mbits/s,195Msamples/s; 4 means
       400Mbits/s,260Msamples/s; 5 means 800Mbits/s,520Msamples/s; L >= 6 means
       = 2^(L-6)*1600Mbits/s, 2^(L-6)*1200Msamples/s.
          The system does not explicitly impose these constraints, since they
       depend upon the intended frame rate -- this can readily be done at the
       application level.
          The second field indicates whether the single-tile (0) or multi-tile
       (1) variation of the profile is specified; the multi-tile variation
       allows for either 1 or 4 tiles per image, where multiple tiles must be
       identical in size and involve either 4 vertical tiles or 2 tiles in each
       direction.    The third field indicates whether the irreversible or
       reversible transform variation of the profile is specified.
          During codestream generation, this parameter attribute defaults to
       the single-tile, irreversible level 1 variant if `Sprofile' or
       `Scpf_profile' equals BROADCAST.
   Simf={<int>,<int>,ENUM<irrev,rev>}
       This parameter attribute provides more specific details for the IMF
       profile or corresponding-profile, associated with one of the labels
       `Sprofile' = IMF or `Scpf_profile' = IMF.  During codestream generation,
       if `Simf' is specified, `Sprofile' will automatically be set to IMF and
       `Sprf_num' will be set accordingly, except where `Scpf_profile' is
       already equal to IMF, in which case the `Simf' attribute is used to
       determine the complete corresponding profile number in `Scpf_num'.
          The first field is the `main-level' of the profile, an integer in the
       range 0 to 11 that describes the maximum number of samples per second,
       taking into account frame rate, frame size and component sub-sampling
       rate, as explained in Ammendment 8 of IS15444-1: 0 means unspecified; 1
       means 65Msamples/s; 2 means 130Msamples/s; 3 means 195Msamples/s; 4
       means260Msamples/s; 5 means 520Msamples/s; and L >= 6 means
       2^(L-6)*1200Msamples/s.  Here 1 Msample/s means 10^6 samples/s.
          The second field is the profile's sub-level, an integer in the range
       0 to 9, which may not exceed the larger of 1 and the main level minus 2;
       its purpose is to identify the maximum bit-rate associated with the
       codestreams: 0 means unspecified; other values L mean 2^L * 10^8 bits/s.
          The final field indicates whether the profile is irreversible or
       reversible, where the irreversible variant is required to be untiled,
       while the reversible case allows for untiled codestreams or tiled
       codestreams with tile dimensions (`Stiles') of 1024x1024, 2048x2048 or
       4096x4096.
          During codestream generation, if `Sprofile' or `Scpf_profile' equals
       IMF, this parameter attribute defaults to the main-level 0, sub-level 0,
       irreversible variant.
   Sextensions={FLAGS<DC|VARQ|TCQ|PRECQ|VIS|SSO|DECOMP|ANY_KNL|SYM_KNL|MCT|NLT|
   ROI>}
       Logical OR of any combination of a number of flags, indicating extended
       features from Part 2 of the JPEG2000 standard which may be found in this
       codestream.  Note that the Kakadu codestream generation machinery will
       set these flags automatically based on features which are detected in
       other parameter objects.  Explanation: DC means arbitrary DC offset;
       VARQ means variable quantization; TCQ means trellis-coded quantization;
       PRECQ means precinct-dependent quantization; VIS means visual masking;
       SSO means single-sample-overlap transform; DECOMP means arbitrary
       decomposition styles; ANY_KNL means arbitrary transform kernels; SYM_KNL
       means arbitrary whole sample symmetric transform kernels; MCT means
       multi-component transform; NLT means non-linear point-transformation
       (formerly called CURVE); and ROI means extended region-of-interest
       signalling.
           [Defaults to 0.]
   Sallowed={FLAGS<EPH|SOP|RGN|PPM|PPT|POC|HET|CHET|RHET|PHET|LYRS|FRAG>}
       This attribute is derived from profile information found in `Sprf_num'
       and `Scpf_num', together with `SCP15_caps', to provide a summary of JPEG
       2000 features that are allowed, through a set of flags -- by default,
       all features are allowed.  You would not normally set this attribute
       yourself, since it is not recorded anywhere in a codestream.  However,
       if you have transcoding requirements or an external profile requirements
       that might not be part of any standard that Kakadu knows about for the
       codestream, you can explicitly supply a set of allowed requirements by
       setting this attribute yourself.  The EPH, SOP, RGN, PPM, PPT and POC
       flags refer to the corresponding marker segments.  The HET flag denotes
       heterogeneous tiles, meaning that tiles can have different coding
       parameters (means tiles-specific COD, COC, QCD and QCC marker segments
       in Part-1 but expands to include other marker segments in other parts,
       wherever these control coding parameters, such as code-block dimension,
       transform structure, transform kernels, multi-component transformation,
       etc.).  The CHET flag denotes heterogeneous components, meaning that the
       code-block dimensions or number of decomposition levels can change
       between image components). The RHET flag means that RGN
       (region-of-interest) marker segments may be tile-specific - this flag
       may not be set unless the RGN flag is set.  Similarly, PHET means that
       POC (progression order change) marker segments may be tile-specific, and
       the flag may not be set unless the POC flag is also set.  The LYRS flag
       means that multiple quality layers are allowed.  The FRAG flag denotes
       fragmented precincts, meaning that the LRCP or RLCP packet progression
       orders may be used with multiple quality layers.
   Srequired={FLAGS<EPH|SOP|TLM|PLT|CPRL|TPTC|REV|IRV|P256|PSMALL|PgeCB|CB5X5|C
   B7X6|CBto6|CBsq56>}
       Like `Sallowed', this attribute is derived from profile information
       found in `Sprf_num', and `Scpf_num', but in this case what is summarized
       are features or parameter values that are required by the profile in
       question.  Again, this attribute is mostly for internal use and is not
       recorded in the codestream, but you can explicitly supply requirements
       that you might have during transcoding or as part of an external profile
       or application specification that is not known to Kakadu.  The EPH, SOP,
       TLM and PLT flags mean that markers (or marker segments) of the same
       name must be used.  CPRL means that the packet progression order must be
       `Corder_CPRL'.  TPTC means that tile-part boundaries must appear between
       packets from different components.  REV means that transforms must be
       reversible, while IRV means that they must be irreversible.  PSMALL,
       P256 and PgeCB are requirements on precinct dimensions: PSMALL means
       precinct area <= 2^16 (2^14 for the lowest resolution level); P256 means
       256x256 precincts 128x128 for the lowest resolution level); and PgeCB
       means that precinct dimensions should be no smaller than the nominal
       code-block dimensions, which is a very weak constraint.  CB5X5, CB7X6,
       CBto6 and CBsq56 are constraints on code-block dimensions: CB5X5 means
       2^5x2^5=32x32 code-blocks are required; CB7X6 means that horizontal
       code-block dimensions are required to be in the range 32-128 and
       vertical code-block dimensions in the range 32-64; CBto6 means
       code-blocks must have width and height no larger than 2^6=64; and CBsq56
       means that code-blocks are square with size 32x32 or 64x64 only.
   Smodes_allowed={FLAGS<BYPASS|RESET|RESTART|CAUSAL|ERTERM|SEGMARK|HT|HTMIX|BY
   PASS_E1|BYPASS_E2>}
       Like `Sallowed' but this attribute describes block coder mode flags that
       are allowed within a profile (`Sprf_num') or a corresponding profile
       (`Scpf_num').  See `Cmodes' for the interpretation of the various mode
       flags here.
   Smodes_required={FLAGS<BYPASS|RESET|RESTART|CAUSAL|ERTERM|SEGMARK|HT|HTMIX|B
   YPASS_E1|BYPASS_E2>}
       Like `Srequired' but this attribute describes block coder mode flags
       that are required within a profile (`Sprf_num') or corresponding profile
       (`Scpf_num').  See `Cmodes' for the interpretation of the various mode
       flags here.  If you explicitly set this attribute during encoding or
       transcoding, the mode flags that you require will be added to any
       requirements derived from profiles, as is done also with `Srequired',
       but it is particularly useful to do this when transcoding a codestream
       to one that includes the `HT' or `HTMIX' modes, since adding these modes
       to `Smodes_required' does not remove any existing compatible mode flags
       (e.g., `CAUSAL') from the `Cmodes' attribute.
   Slevels_allowed={<int>,<int>}
       Like `Sallowed' but this attribute describes the number of decomposition
       levels (`Cdecomp') that are allowed, taking profile constraints into
       account.  The first and last parameters are inclusive lower and upper
       bounds, respectively, which default to 0 and 32, being the absolute
       limits supported by JPEG 2000 as a whole.
   Scap={FLAGS<P2|P10|P15|P17|NOTP2|PALL>}
       This attribute identifies the presence of technology from various parts
       of the JPEG 2000 family of standards, which the exception of Part-1. 
       Currently, only 4 flags are defined: P2 for Part-2; P10 for Part-10; P15
       for Part-15 and P17 for Part-17.  Additional information about the
       capabilities required to fully understand the codestream are contained
       within parameter attributes whose name is prefixed by `SCP2_' (for
       Part-2), `SCP10_' (for Part-10), `SCP15_' (for Part-15) and `SCP17_'
       (for Part-17).  Currently, the only relevant capability attributes are
       `SCP2_caps', `SCP15_caps', `SCP15_magb' and `SCP17_caps'.  If such
       attributes are specified, the relevant flags (e.g., `P2', `P15' or
       `P17') are introduced to the `Scap' attribute.  The flags in this
       attribute are all derived from a CAP marker segment during codestream
       parsing, except that the P2 flag is also asserted whenever Part-2
       technologies are detected, even if there is no CAP marker segment.  You
       do not need to set `Scap' explicitly yourself during codestream
       generation, although it can be useful.  For example, if `Scap' is set
       explicitly to include the `P15' flag, then the default value for
       `Cmodes' becomes `HT' (the Part-15 HT block coder), as opposed to 0. 
       More commonly, you would set the actual capabilities that are associated
       with the `Scap' flags, such as `Sextensions', `SCP2_caps', `SCP15_magb',
       `SCP15_caps' and `SCP17_caps', along with others; moreover, these
       themselves are often configured automatically based on the presence or
       values of other attributes.
          The special values `NOTP2' and `PALL' are used only during parsing,
       to record the fact that bit-14 of the Rsiz field in the SIZ marker
       segment is set, pending the discovery of which parts are actually active
       when the CAP marker segment is parsed.  The `NOTP2' value asserts all
       flags in `Scap' other than P2, and is used if bit-14 of Rsiz is 1 but
       bit-15 is 0.  The `ALL' value asserts all flags in `Scap', and is used
       if bits 14 and 15 are both set within the Rsiz field of the SIZ marker
       segment.
   Sncap={FLAGS<P2|P10|P15|P17|NOTP2|PALL>}
       This attribute does not map to any information recorded in the
       codestream.  It is used only during codestream generation, to explicitly
       disallow the use of sets of capabilities that would otherwise need to be
       signalled via `Scap'.  The main application for this attribute is in
       transcoding, where an incoming codestream identifies use of technology
       from certain parts of the JPEG 2000 family of standards that you want to
       remove during the transcoding process.  For example, to transcode a
       Part-15 codestream that uses the HT block coder to a pure Part-1
       codestream it is sufficient to set `Sncap' to P15 (meaning the
       codestream should NOT have Part-15 capabilities) and to set `Cmodes=0',
       disabling the HT and HTMIX code-block mode flags.  You can use the
       `PALL' value to disallow all capabilities other than those associated
       with JPEG 2000 Part-1, and you can use `NOTP2' to disable all
       capabilitities other than those associated with Parts 1 and 2 of JEPG
       2000.
   SCP2_caps={FLAGS<EXTENDED_COD>}
       Identifies capability extensions that are found in ammendments to Part-2
       of the JPEG2000 family of standards.  Currently, only two such
       capabilities are defined.  EXTENDED_COD identifies the possible presence
       of Part-2 block-coder extensions in COD/COC marker segments.  This
       capability was introduced with IS15444-2/AMD4.
           [Defaults to 0.]
   SCP15_magb={<int>}
       If this attribute exists and has non-zero parameter value, the use of
       Part-15 (High Throughput JPEG 2000) technologies is indicated -- notably
       use of the HT block coding algorithm is at least possible, if not
       required, in all codestreams with non-zero `SCP15_magb' value B.  If B
       is 0, Part-15 technology is deemed not to apply, and the `SCP15_caps'
       attribute is ignored, while the `Scap_P15' flag is removed from any
       `Scap' attribute.
          The integer parameter B provides a global bound on the sample
       magnitudes M that can be produced by any HT Cleanup pass, where M =
       floor(|X|/2^p), with X the original quantized subband sample, and p the
       bit-plane associated with the HT Cleanp pass -- i.e., p is the number of
       magnitude LSBs that are discarded by the Cleanup pass in question.  The
       bound B applies only to code-blocks that are processed by the Part-15 HT
       block coding algorithm.  The meaning of bound B depends on whether the
       associated subband b is obtained using a reversible DWT (R) or an
       irreversible DWT (I), as well as the decomposition level n_b of the
       subband -- n_b is used by the implicit quantization step size derivation
       algorithm (see `Qderived') and can be a multiple of 1/2 in Part-2.  For
       the reversible case (R) or where B > 31, all HT Cleanup pass magnitudes
       M satisfy
                 log_2(M) < B.
       Otherwise, HT Cleanup pass magnitudes satisfy
              log_2(M) < min{31, B+ceil(n_b)-1}.
       The value of B is encoded within the low 5 bits of the LSB as max{0,
       B-8} if B <= 27, else as min{31, 19+ceil(B-27)/4)}.
          Even though the CAP marker segment cannot encode B values smaller
       than 8, any value larger than 1 will be enforced during codestream
       generation and then encoded using the smallest compatible bound in the
       CAP marker segment.
          During content generation, if `SCP15_magb' is equal to 1, or
       `SCP15_caps' has not been specified, but the Part-15 HT block coder has
       been used (i.e., if `Cmodes' includes `Cmodes_HT'), a value for B is
       selected automatically based on the quantization parameters, but subject
       to any limit supplied via the `SCP15_limb' attribute.  The Kakadu
       encoding machinery will never select a value of B that is greater than
       31, since this is a reasonable internal limit for a software-based
       decoder and also a current constraint on Kakadu's encoder
       implementation.  As a protection against unintentionally demanding too
       much of a third party decoder implementation, if a `Qfactor' is not
       specified, B values that are derived automatically for irreversibly
       transformed content, based on quantization parameters are artificially
       capped at 14, which is a reasonable bound for most photographic
       applications.  You can override this by specifying a larger value
       explicitly, or by using `Qfactor' as a disciplined way of selecting
       quantization parameters.  Where a reversible transform is used to
       produce subbands coded using the HT block coder, the B value is adjusted
       upwards sufficiently to achieve lossless coding, regardless of whether
       it is generated automatically or supplied expicitly to start with,
       subject only to any constraint provided by `SCP15_limb'.
   SCP15_limb={<int>}
       This is a pseudo-attribute, used during encoding or transcoding, to
       constrain the selected value for `SCP15_magb'.  See the description of
       that attribute for an explanation.  By default, no limit is applied.
   SCP15_caps={FLAGS<IRV|HET|RGN|SETS|MIX|ORIG>}
       This attribute is used together with `SCP15_magb' to describe the 16-bit
       capabilities field Ccap15 in the CAP marker segment of a Part-15
       codestream.  If both attributes are missing, or if `SCP15_magb' exists
       and is 0, there is or will be no Ccap15 field (perhaps also no CAP
       marker segment) and the codestream does not conform to Part-15 of the
       JPEG 2000 spec.  If this attribute exists but `SCP15_magb' does not,
       during codestream generation, the behaviour is as if `SCP15_magb' were
       1, in which case a suitable magnitude bound value is selected
       automatically.  If `SCP15_magb' exists with non-zero value, but
       `SCP15_caps' does not exist, default values for the `MIX', `ORIG' and
       `IRV' flags are selected automatically based on other coding parameter
       attributes, but the default flags may still result in the generation of
       incompatibility errors if they are found to be inconsistent with actual
       coding parameters, requiring you to explicitly set the `SCP15_caps'
       attribute.
          The `IRV' flag means that an irreversible wavelet transform may be
       used to produce subband samples that are coded using the HT block coding
       algorithm.  This affects the interpretation of the magnitude bound
       parameter B, as explained with the `SCP15_magb' attribute.
          The `HET' flag means that heterogenous tile encodings might exist,
       meaning that coding parameters or progression order changes (see
       `POCorder') or packed packet headers (PPT marker segments) might exist
       within tile-part headers.
          The `RGN' flag means that a max-shift encoded region of interest is
       permissible (see the `Rshift' attribute).  This affects the maximum
       sensible value for the magnitude bound parameter B associated with
       `SCP15_magb'; if this flag is missing, the maximum sensible B value is
       37.  The sensible limits are always applied during codestream
       generation.
          The `SETS' flag means that multiple HT Sets of coding passes might
       exist for a code-block (very unusual, since it introduces redundancy
       into the codestream).
          The `MIX' flag means that a tile-component or even a precinct may
       contain a mixture of code-blocks that use the original J2K block coding
       algorithm and code-blocks that use the Part-15 HT block coder.
          The `ORIG' flag means that code-blocks might use the original J2K
       block coding algorithm, rather than the Part-15 HT block coder.  If the
       `MIX' flag is present, `ORIG' is automatically introduced.
   SCP17_caps={<int>}
       Identifies capability extensions that belong to Part-17 of the JPEG2000
       family of standards. Currently, this is just a placeholder, so the only
       valid value is 0.
   Ssize={<int>,<int>}
       Canvas dimensions: vertical dimension first.
           [For compressors, this will normally be derived from the dimensions
           of the individual image components. Explicitly supplying the canvas
           dimensions may be desirable if the source image files do not
           indicate their dimensions, or if custom sub-sampling factors are
           desired.]
   Sorigin={<int>,<int>}
       Image origin on canvas: vertical coordinate first.
           [Defaults to {0,0}, or the tile origin if one is given]
   Stiles={<int>,<int>}
       Tile partition size: vertical dimension first.
           [Defaults to {0,0}]
   Stile_origin={<int>,<int>}
       Tile origin on the canvas: vertical coordinate first.
           [Defaults to {0,0}]
   Scomponents={<int>}
       Number of codestream image components.
           [For compressors, this will normally be deduced from the number and
           type of image files supplied to the compressor.  Note carefully,
           however, that if a multi-component transform is used, the number of
           codestream image components might not be equal to the number of
           `output image components' given by `Mcomponents'.  In this case, the
           value of `Mcomponents' and the corresponding `Mprecision' and
           `Msigned' attributes should generally be associated with the image
           files being read (for compression) or written (for decompression).]
   Ssigned={<yes/no>},...
       Indicates whether each codestream image component contains signed or
       unsigned sample values.  Compression applications that derive precision
       and signed/unsigned information from input image files are recommended
       to explicitly set `Nsigned' only, leaving the internal machinery to
       automatically transfer `Nsigned' values to `Ssigned', which happens
       whenever there is no Part-2 multi-component transform (i.e.,
       `Mcomponents'=0).  If there is a multi-component, `Nsigned' is usually
       sufficient to deduce `Msigned' automatically, but you will need to
       explicitly specify `Ssigned'.  If any value for `Ssigned' is specified
       explicitly, all values must be specified -- missing values are derived
       by auto-replicating the last value that was specified.
   Sprecision={<int>},...
       Indicates the bit-depth of each codestream image component.  Compression
       applications that derive precision and signed/unsigned information from
       input image files are recommended to explicitly set `Nprecision' only,
       leaving the values to be copied to `Sprecision' automatically.  If there
       is a Part-2 multi-component transform (`Mcomponents' != 0), however,
       `Nprecision' is usually sufficient to deduce `Mprecision' automatically,
       but you will need to explicitly specify `Sprecision'.  If any value for
       `Sprecision' is specified explicitly, all values must be specified --
       missing values are derived by auto-replicating the last value that was
       specified.
   Ssampling={<int>,<int>},...
       Indicates the sub-sampling factors for each codestream image component.
       In each record, the vertical factor appears first, followed by the
       horizontal sub-sampling factor. The last supplied record is repeated
       indefinitely for all remaining components.
           [For compressors, a suitable set of sub-sampling factors will
           normally be deduced from the individual image component dimensions.]
   Sdims={<int>,<int>},...
       Indicates the dimensions (vertical, then horizontal) of each individual
       image component. The last supplied record is repeated indefinitely for
       all remaining components.
           [For compressors, the image component dimensions will normally be
           deduced from the image files supplied to the compressor, but may be
           explicitly set if raw input files are to be used.]
   Mcomponents={<int>}
       Number of image components produced at the output of the inverse
       multi-component transform -- during compression, you may think of these
       as original image comonents.  In any event, we refer to them as "MCT
       output components", taking the perspective of the decompressor.  The
       value of `Mcomponents' may be smaller than or larger than the
       `Scomponents' value, which refers to the number of "codestream image
       components".  The codestream image components are supplied to the input
       of the inverse multi-component transform.  Note carefully, however, that
       for Kakadu to perform a forward multi-component transform on image data
       supplied to a compressor, the value of `Mcomponents' must be at least as
       large as `Scomponents' and the inverse multi-component transform must
       provide sufficient invertible transform blocks to derive the codestream
       components from the output image components.  In the special case where
       `Mcomponents' is 0, or not specified, there is no multi-component
       transform.  In this case, `Scomponents', `Ssigned' and `Sprecision'
       define the output image components.  [Defaults to 0.  You must
       explicitly set a non-zero value for this attribute if you want to use
       Part-2 multi-component transforms.  Compressors might be able to deduce
       this information from the input files, if they are aware that you want
       to perform a multi-component transform.]
   Msigned={<yes/no>},...
       Indicates whether each MCT output component (see `Mcomponents' for a
       definition of "MCT output components") contains signed or unsigned
       sample values.  Compressors that obtain precision and signed/unsigned
       information from input image files are recommended to use this
       information to explicitly set `Nsigned', leaving `Msigned' to be deduced
       automatically (so long as `Mcomponents' > 0). The only condition under
       which `Msigned' and `Nsigned' need to be explicitly specified separately
       is where a non-linear point transform (see `NLType') needs to change the
       signed characteristics of its samples -- probably not common.  If you do
       specify any `Msigned' values, you need to supply them all, or be content
       with the auto-replicating policy that replicates the last specified
       value as required.
   Mprecision={<int>},...
       Indicates the bit-depth of each MCT output component (see `Mcomponents'
       for a definition of "MCT output components").  Compressors that obtain
       precision and signed/unsigned information from input image files are
       recommended to use this information to explicitly set `Nprecision',
       leaving `Mprecision' to be deduced automatically (so long as
       `Mcomponents' > 0).  The only condition under which `Mprecision' and
       `Nprecision' need to be explicitly specified separately is where a
       non-linear point transform (see `NLType') needs to change the precision
       of its samples.  If you do specify any `Mprecision' values, you need to
       supply them all, or be content with the auto-replicating policy that
       replicates the last specified value as required.
   Ncomponents={<int>}
       Number of image components produced at the ultimate output of the
       decompression process, after applying any required multi-component
       transform and any non-linear point transforms that may be defined. If
       `Mcomponents' is non-zero (i.e., if there is a Part-2 multi-component
       transform), `Ncomponents' and `Mcomponents' must be identical, so it is
       not strictly necessary to explicitly specify `Ncomponents' -- it can be
       auto-deduced.  If `Mcomponents' = 0, the values of `Ncomponents' and
       `Scomponents' must be identical, so again it is not strictly necessary
       to specify both.
   Nsigned={<yes/no>},...
       Plays the same role as `Msigned' and `Ssigned', but describes the
       ultimate signed/unsigned attributes of the samples produced during
       decompression after applying any non-linear point transform. 
       Compressors are recommended to explicitly specify `Nsigned', leaving the
       internal machinery to automatically deduce `Msigned' or `Ssigned' from
       `Nsigned' (by copying).  If there is no Part-2 multi-component
       transform, `Ssigned' will be copied from `Nsigned' or vice-versa if
       either is not specified.  If there is a Part-2 multi-component transform
       (i.e., `Mcomponents' > 0), `Msigned' will be copied from `Nsigned' or
       vice-versa if either is not explicitly specified.  If you do specify any
       `Nsigned' attribute value, you must specify all `Ncomponents' of them or
       be content with the auto-replicating policy that replicates the last
       specified value as required.
   Nprecision={<int>},...
       Plays the same role as `Mprecision' and `Sprecision', but describes the
       ultimate precision of the samples produced during decompression after
       applying any non-linear point transform.  Compressors are recommended to
       explicitly specify `Nprecision', leaving the internal machinery to
       automatically deduce `Mprecision' or `Sprecision' from `Nprecision' (by
       copying).  If there is no Part-2 multi-component transform, `Sprecision'
       will be copied from `Nprecision' or vice-versa if either is not
       specified.  If there is a Part-2 multi-component transform (i.e.,
       `Mcomponents' > 0), `Mprecision' will be copied from `Nprecision' or
       vice-versa if either is not explicitly specified.  If you do specify any
       `Nprecision' attribute value, you must specify all `Ncomponents' of them
       or be content with the auto-replicating policy that replicates the last
       specified value as required.
   Scbr={<int>,<float>}
       This attribute is currently used only during content generation; it is
       not actually recorded in any marker segment in the codestream.  The
       presence of an `Scbr' attribute means that incremental flushing should
       be performed, or at least simulated (all content can still be flushed at
       the end) subject to a low latency objective.  The two parameters specify
       an integer flushing interval V and the maximum size Bmax of a notional
       "leaky bucket" that is inserted between the incremental flushing process
       and a constant rate data channel.  We now briefly explain these
       concepts.
          The packet progression sequence (`Corder') for each tile is must be
       PCRL, and there will usually only be one tile.  No extra tile-parts are
       currently allowed, so each tile (usually just one) undergoes a series of
       flush operations that are separated by V rows of lowest resolution
       precincts from the lowest resolution of the first tile's first
       codestream component.  That is, each flush-set commences with the first
       packet from precinct row V*k of the lowest resolution in tile-component
       0, where k=0,1,2,...  Normally, V will be 1, and precinct dimensions
       will be chosen such that all flush sets involve the same number of
       packets/precincts, except possibly the last one.  If image components
       have different sizes, you will most likely need to adjust the number of
       vertical decomposition levels and the precinct dimensions on a
       per-component basis to ensure that all components can flush the same
       number of precincts in each flush set.
          The leaky bucket size Bmax is measured in terms of lines from the
       first codestream image component.  Bmax need not be an integer, but it
       will be converted internally to a leaky bucket size that is measured in
       bytes.  Bmax must be at least as large as the number of lines from the
       first component in each flush-set.  Normally, Bmax should be larger than
       this, so as to give the rate control algorithm some flexibility.  The
       overall target size L for the codestream, is converted to a data rate D
       = L/T, where T is the total number of samples in all subbands of the
       codestream.  The gap between one flush set and the next is considered to
       be S, where S is the number of samples in the flush set.  Notice that we
       are measuring time in terms of image samples, so the actual time gap
       between the flush sets is S/Rsample, where Rsample is the image sample
       data rate (samples/second), while the CBR channel has a data rate of
       D*Rsample bytes/second.  This inter-flush separation model provides a
       valid mechanism for assessing the delay attributed to communication, so
       long as all flush sets (except possibly the last one) have the same
       structure, so that flush sets naturally become available at a constant
       rate from the compressor; an informative error message is generated if
       this is not the case.  The maximum delay associated with the leaky
       bucket model is then Bmax*Weff/Rsample seconds, where Weff is an
       effective image width, being the width of the first component multiplied
       by the ratio between the total number of image samples and the number of
       samples in the first component.
          The codestream main header is included as part of the first flush
       set, while the EOC marker is included as part of the last flush set. 
       Apart from this, the first flush set of every tile includes that tile's
       tile-part header in its byte count.  According to the foregoing model,
       the leaky bucket may not be filled beyond Bmax*Weff*D bytes as a result
       of any given flush, after which S*D bytes are drained from the bucket (S
       is the number of samples in the flush) before the next flush. 
       Accordingly, each flush must fill the bucket to at least S*D bytes (to
       avoid underflow) but to no more than Bmax*Weff*D bytes.  The last flush
       in the codestream is a little different; it must fill the bucket to no
       more than S*D bytes, so that the total number of bytes dumped into the
       bucket by all flush operations does not exceed L, but it is allowed to
       output fewer bytes; this is because we assume that spacer bytes will be
       introduced between codestreams in low latency CBR applications, so that
       each codestream occupies exactly L bytes; there is then no need to worry
       about buffer underflow or codestream indexing.
   Creslengths[:<TC>]={<int>},...
       (ENCODER Meta-Attribute):  Maximum number of compressed bytes (packet
       headers plus packet bodies) that can be produced for each successive
       image resolution, starting from the highest resolution and working down
       to the lowest.  The limit applies to the cumulative number of bytes
       generated for the resolution in question and all lower resolutions.  If
       the attribute is global to the entire codestream (no T or C specifier),
       the limit for each resolution applies to the cumulative number of bytes
       up to that resolution in all tiles and all image components.  If the
       attribute is tile-specific but not component-specific, the limit for
       each resolution applies to the cumulative number of bytes up to that
       resolution for all image components within the tile.  If the attribute
       is component-specific, the limit applies to the cumulative number of
       bytes up to the resolution in question across all tiles, but only in
       that image component.  Finally, if the attribute is component-specific
       and tile-specific, the limit applies to the cumulative number of bytes
       up to the resolution in question, within just that tile-component.  You
       can provide limits of all four types.  Moreover, you need not provide
       limits for all resolutions. The initial set of byte limits applies only
       to the first quality layer to be generated during compression.  Limits
       for additional quality layers may be supplied by inserting zero or
       negative values into the list; these are treated as layer delimiters. 
       So, for example, the parameter string "1000,700,0,3000,2000,0,10000"
       provides limits of 1000 and 700 bytes for the highest and second highest
       resolutions in the first quality layer, 3000 and 2000 bytes for the same
       resolutions in the second quality layer, and a limit of 10000 bytes only
       to the highest resolution in the third quality layer.  Any subsequent
       quality layers are not restricted by this parameter attribute.  Note
       that each quality layer that is affected by the `Creslengths' attribute
       should be governed by an explicit target length (i.e., target bit-rate)
       or an explicit target distortion-length slope for rate-control purposes.
       Implicit target lengths (or bit-rates), corresponding to zero-valued
       entries in the array of target lengths passed to `kdu_codestream::flush'
       or an equivalent function, may produce unexpected outcomes when used
       with the `Creslengths' attribute.  Note also that `Creslengths'
       constraints will not currently be applied correctly if incremental
       codestream flushing is used -- this can be arranged if a significant
       need arises for the combined functionality.  Finally, note that the
       interpretation of the `Creslengths' attribute may be modified by the
       presence of a `Cagglengths' attribute.
   Cagglengths[:<TC>]={<int>},...
       (ENCODER Meta-Attribute):  This attribute has meaning only when used in
       conjunction with `Creslengths'.  Moreover, only component specific and
       tile-component specific forms of the `Cagglengths' attribute are
       meaningful.  Suppose the attribute is applied to image component C; then
       the attribute directs the rate control machinery to combine (aggregate)
       the compressed bytes (packet headers plus packet bodies) generated for
       each successively lower resolution of component C with the corresponding
       compressed bytes generated for a (possibly different) specified image
       component, whose `Creslengths' constraints shall be used to constrain
       the aggregated total.  The first parameter identifies the image
       component index c_0 (zero based) with which the full compressed data
       tally for component C should be aggregated before applying the
       corresponding `Creslengths' constraint for component c_0.  The next
       parameter identifies the image component index c_1 with which the next
       lower resolution compressed data tally for component C should be
       aggregated, and so forth.  The last supplied parameter is replicated
       (extrapolated) as required to cover all resolutions for component C. 
       The purpose of the `Cagglengths' attribute is to provide a means for
       explicitly constraining the aggregated amount of data generated for
       specific sets of image components.  Multiple image components C may
       direct their cumulative compressed data tallies to be aggregated with
       any given other component prior to assessing `Creslengths' constraints. 
       If a component index supplied with the `Cagglengths' attribute
       identifies an image component that does not exist, or that has no
       component-specific `Creslengths' constraints, no constraints will apply
       in regard to that resolution of the component to which the `Cagglengths'
       attribute belongs.  Tile-component specific forms of the `Cagglengths'
       attribute describe the aggregation of cumulative compressed byte counts
       from one tile-component with another tile-component in the same tile,
       the aggregated total being subjected to any constraints supplied via a
       `Creslengths' attribute for the target tile-component.
   Cplex[:<TC>]={<int>,ENUM<NONE,FIX,WFIX,EST>,<float>,<int>}
       (ENCODER Meta-Attribute):  This attribute controls complexity
       constrained encoding, especially for images, but can also be used for
       video, when using the HT block coding algorithm (i.e., where `Cmodes'
       contains the HT flag).  The high-throughput block encoder does not need
       to start from the coarsest significant bit-plane when generating content
       for the Post-Compression Rate-Distortion optimization (PCRD-opt) phase
       of the standard Kakadu rate control procedure.  Instead, it can start
       from a later (finer) bit-plane if we can be confident that coarser
       quantization would not be required to satisfy coded length constraints. 
       The first (integer) parameter identifies the maximum number of coding
       passes Z to perform, for which a typical value would be 6 (2 full
       HT-Sets, each with Cleanup, SigProp and MagRef coding passes).  It is an
       error to supply Z values smaller than 1, unless the second parameter is
       NONE.  The second parameter must be one of the enumerated values NONE,
       FIX, WFIX or EST, which identify the complexity constraint method.  If
       the method is NONE, the other parameters are ignored and there are no
       complexity constraints.  The other methods are described separately
       below.  In all cases, if the internal machinery has been informed that
       there are no compressed length or distortion-length slope targets (it
       should be so-informed in a performant implementation via a call to
       `kdu_codestream::set_max_slope_threshold'), then the HT block encoder
       will always generate just the finest (highest quality) Cleanup pass, and
       so the `Cplex' attribute is ignored.
          In the `Cplex' FIX method, the 1st coding pass (a Cleanup pass)
       corresponds to discarding D finest bit-planes from the quantized values,
       where D=round(F) and F is the value of the third parameter.  For the FIX
       method, the fourth (integer) parameter has no meaning but must be 0. So,
       for example, "Cplex=2,FIX,1,0" would result in the generation of 2
       coding passes, corresponding to the 2'nd last Cleanup pass and the
       following SigProp pass, but not the final MagRef or Cleanup passes.  The
       FIX method can be used in conjunction with a target compressed length or
       a target distortion-length slope threshold; in each case, the PCRD-opt
       algorithm is applied to the limited set of generated coding passes that
       survive the complexity constraints.  If there is neither a target length
       nor a target slope threshold, the
       `kdu_codestream::set_max_slope_threshold' function should normally be
       invoked with an argument of 0, to inform the system that there is no
       basis for any kind of rate control, so it is sufficient to just generate
       the finest (highest quality) Cleanup pass; in that case, the `Cplex'
       attribute has no effect, as explained above.
          The `Cplex' WFIX method is similar to FIX, but we incorporate
       weighting factors u_b that equalize the significance of the LSB in each
       subband b's quantized samples; here, u_b takes into account the
       quantization step sizes, the square-root of the energy gain factors
       associated with all relevant transform steps, and any additional weights
       that may have been supplied via `Cband_weights', `Cweight' and/or
       `Clev_weights' attributes.  These factors are normalized to the range 0
       to 1.0.  The number of discarded bit-planes D assoiated with the coasest
       coding pass is then subband specific, and may be written as D_b = max{0,
       round(F - log_2(u_b)}.  Note that the third Cplex parameter F is
       real-valued and can be negative.  If all quantization step sizes are
       derived from a single `Qstep' attribute using Kakadu's default
       procedure, and if no visual or other subband weights are applied, all
       u_b factors will be 1.0, so that the WFIX and FIX methods are identical.
       Like FIX, the WFIX method can be used successfully in conjunction with a
       target compressed length or a target distortion-length slope threshold,
       and the fourth parameter has no meaning, but is required to be 0.
          The most important `Cplex' method is EST.  This is similar to the
       WFIX method, incorporating the weights W_b required to equalize
       significance across subbands, but the global offset F for WFIX is
       replaced by a quantity that is dynamically estimated from the subband
       statistics so as to reasonably ensure that the target compressed length
       can be achieved.  In this case, the third (real-valued) parameter is
       P+rho, where `P' is a non-negative integer (usually 0) that is added
       directly to the gobal offset F, and `rho' is a fractional bias in the
       range 0 <= `rho' < 1.  With P=0, a bias of rho=0.0 encourages the
       selection of F values that push the number of compressed bytes
       associated with the first of the Z coding passes as close as reasonably
       possible to the compressed length, while still almost surely
       guaranteeing that the target length is not exceeded.  A value of `rho'
       close to 1.0 encourages the selection of F values such that the byte
       count associated with a fourth coding pass (i.e., one extra bit-plane)
       is closer to the target compressed length. In practice, neither of these
       extremes is usually desirable. If Z is small (say Z=3) you might set rho
       to a very small value, while if for a typical value of Z=6, you are
       encouraged to choose a value of around 0.25, unless you have experience
       to suggest otherwise.  Usually, the integer part P of the third
       parameter will be 0, but if you are prepared to produce even more coding
       passes, P can be used to help centre the generated passes around the
       most desirable operating point for the target compressed length.  For
       example, with Z=9, you might choose P=1 (e.g., with a third parameter
       value of 1.25, keeping the bias `rho' to 0.25), which will result in the
       generation of one full set of 3 codig passes that are coarser than we
       expect to need.  For the EST method, the fourth (integer) parameter T
       can be understood (roughly) as the number of image lines by which the
       block encoding processes should "trail" the generation of all relevant
       subbands -- a kind of delay that you can control to trade memory/latency
       for reliability of the estimates.  The T value is interpreted relative
       to the full resolution tile-component, but you can specialize this
       attribute to each individual tile, component or tile-component.  So, for
       example, Cplex={6,EST,0.25,256} and Cplex:C0={6,EST,0.25,512} together
       would result in a statistics-gathering delay of 256 lines for all but
       component 0 which has a delay of 512 lines.  This could be useful in
       compresing content with sub-sampled chrominance.  Large estimation
       delays, approaching the full tile height, can be expressed more
       conveniently using negative T values; negative values are automatically
       added to the tile height to come up with the intended delay.  Thus, for
       example, Cplex={6,EST,0.25,-64} means that block coding is delayed at
       least until all subband samples for all but the last 64 tile lines have
       been generated and made available for statistical analysis.
          The most useful configurations are Cplex={6,EST,0.25,0} (minimum
       memory) and Cplex={6,EST,0.25,-1} (maximum memory).  We recommend the
       second configuation mostly in conjunction with the `Scbr' attribute, for
       low-latency compression applications, since the amount of delay/memory
       is bounded by the size of a CBR flush-set in that case, which is usually
       very small; moreover, with the `Scbr' attribute, high memory forms of
       the Cplex EST method exhibit deterministic behaviour in multi-threaded
       settings.
          If no global compressed length target is set (internally via a call
       to `kdu_codestream::set_max_bytes'), the EST method has no basis for its
       estimates and so the `Cplex' attribute will be ignored, but an
       informative warning message is generated, except where the `Cplex'
       attribute would be ignored anyway, as explained above.
   
   Cvis[:<TC>]={<float>}
       (ENCODER Meta-Attribute):  Activates a human visual contrast masking
       model that can improve visual quality at a given bit-rate, so long as
       the image is large and contains sufficiently diverse content.  This
       option should be more effective with smaller code-block sizes (e.g.,
       Cblk={32,32}), but can work quite well even with the default block size
       of 64x64.  The single real-valued parameter is interpreted as a
       "visibility floor", typically in the range of 0.01 to 0.0001. 
       Notionally, the visibility floor is equal to the amplitude of the
       smallest subband signal that can be detected; this is expressed relative
       to the unit nominal range convention, in which 0.5 is the maximum
       amplitude one could possibly get in any subband, in response to any
       sinusoidal input stimulus.  At or below this detection threshold, the
       strength of neighbouring subband samples is considered to have no impact
       on the visibility of quantization artifacts.  Above the visibility
       floor, their masking impact is considered to grow as the square root of
       their amplitude.  Another way to understand the visibility floor is that
       its reciprocal is the maximum amount by which the distortion
       contribution from any sample can be magnitied via the contrast masking
       mechanism.  For example, a value of 0.01 yields squared error distortion
       magnification factors in the range 2 to 100 (i.e., a range of 50:1),
       which is equivalent to adjusting `Cband_weights' values through a range
       of roughly 7:1 in a spatially varying, content dependent manner -- note
       that the `Cband_weights' and other global weighting factors are all
       squared before being applied to squared error distortion contributions. 
       This option is somewhat experimental at the current time.
   Cweight[:<TC>]={<float>}
       (ENCODER Meta-Attribute):  Multiplier for subband weighting factors (see
       `Clev_weights', `Cband_weights' and `Ctype' below).  Scaling all the
       weights by a single quantity has no impact on their relative
       significance.  However, you may supply a separate weight for each
       component, or even each tile-component, allowing you to control the
       relative signicance of image components or tile-components in a simple
       manner.
   Clev_weights[:<TC>]={<float>},...
       (ENCODER Meta-Attribute):  Weighting factors for each successive
       resolution level, starting from the highest resolution and working down
       to the lowest (but not including the LL band!!).  The last supplied
       weight is repeated as necessary.  Weight values are squared to obtain
       energy weights for weighted MSE calculations.  The LL subband always has
       a weight of 1.0, regardless of the number of resolution levels. 
       However, the weights associated with all subbands, including the LL
       band, are multiplied by the value supplied by `Cweight', which may be
       specialized to individual components or tile-components.  Although
       similar to `Cband_weights', that attribute is special in that it can be
       automatically derived from `Ctype', while `Clev_weights' provides
       additional weighting factors over and above those derived in this way. 
       Use `Clev_weights' with caution, preferring `Cband_weights' instead, if
       you want to explicitly specify weighting factors that will not be
       combined with subband specific weights that might be installed
       automatically behind the scenes.
   Cband_weights[:<TC>]={<float>},...
       (ENCODER Meta-Attribute):  Weighting factors for each successive
       subband, starting from the highest frequency subbands and working down
       (i.e., HH1, LH1, HL1, HH2, ...). The last supplied weight is repeated as
       necessary for all remaining subbands (except the LL band). If
       `Clev_weights' is also supplied, both sets of weighting factors are
       combined (multiplied).  Weight values are squared to obtain energy
       weights for weighted MSE calculations.  The LL subband always has a
       weight of 1.0, which avoids problems which may occur when image
       components or tiles have different numbers of resolution levels.  To
       modify the relative weighting of components or tile-components,
       including their LL subbands, use the `Cweight' option; its weighting
       factors are multiplied by those specified using `Cband_weights' and
       `Clev_weights'.  If the `Cdecomp' attribute is used to describe more
       general packet wavelet transforms, all subbands obtained by splitting an
       HL, LH or HH subband will be assigned the same weight.  No mechanism is
       currently provided for specifying their weights separately.  Moreover,
       all three weights (HL, LH and HH) are present for each resolution level,
       even if that level only involves horizontal or vertical splitting, and
       even in the degenerate case of no splitting at all.  For horizontal
       splitting only, subbands derived from HX use the corresponding HL
       weight; HH and LH weights are then ignored.  Similarly for vertical
       splitting only, subbands derived from XH use the corresponding LH
       weight; HH and HL weights are then ignored.
           [If `Cband_weights' is not specified, but `Ctype' (component-type)
           is, then values for this attribute are installed automatically,
           based on component type, possibly depending upon the `Qfactor'
           value, if specified.]
   Ctype[:<T>]={ENUM<N,Y,Cb,Cr,C>},...
       (ENCODER Meta-Attribute):  This attribute is used together with
       `Qfactor' and `Qfparams' to synthesize default values for
       `Cband_weights', if not specified explicitly.  Indeed it is preferable
       to use these default (visual) subband weighting factors, rather than
       explicitly specifying `Cband_weights' attributes yourself, unless you
       really know what you are doing.  The derived values do not depend on the
       existence of `Cweight' or `Clev_weights' attributes, but if those are
       specified then they combine with any synthesized `Cband_weights' values,
       as described with the `Cband_weights' attribute.  This attribute takes
       multiple scalar records, describing each of the components that are
       subjected to spatial wavelet transformation and encoding -- these are
       the components produced after any multi-component transformation during
       encoding, including the Part-1 reversible (RCT) or irreversible (ICT)
       component decorrelating transform.  The last supplied record is
       replicated as required, so it is not strictly necessary to supply one
       record for every component.  Each record take one of an enumerated set
       of values, with the following interpretations.
          N=0 identifies a non-visual component, for which `Cband_weights' is
       simply set to 1.0.
          Y=1 identifies a luminance component, for which the default
       `Cband_weights' values, from the highest resolution HH subband down,
       are: 0.0901, 2x 0.2758, 0.7018, 2x 0.8378, 1.0.
          Cb=2 identifies a blue-luma visual opponent colour channel, as
       produced by the JPEG 2000 ICT (2nd channel), which is equivalent to the
       Cb channel of the YCbCr colour space, and similar to the V (3rd channel)
       of YUV and the Db (2nd channel) of the JPEG 2000 RCT, with
       `Cband_weights' values of 0.0263, 2x 0.0863, 0.1362, 2x 0.2564, 0.3346,
       2x 0.4691, 0.5444, 2x 0.6523, 0.7078, 2x 0.7797, 1.0.
          Cr=3 identifies a red-luma visual opponent colour channel, as
       produced by the Part-1 ICT (3rd channel), and similar to the U (2nd
       channel) of YUV and the Dr (3rd channel) of the Part-1 RCT, with
       `Cband_weights' values of 0.0773, 2x 0.1835, 0.2598, 2x 0.4130, 0.5040,
       2x 0.6464, 0.7220, 2x 0.8254, 0.8769, 2x 0.9424, 1.0.
          Finally, the C=4 option identifies a generic chrominance channel that
       is assigned the larger of the Cb or Cr weights described above.
          If Cb, Cr or C is used for some component, Y must be used for at
       least one component, and the first Y component is used as a reference to
       determine whether the chrominance channels have been sub-sampled.  If
       so, the visual weights assigned to chrominance subbands are adjusted
       upwards to approximately reflect their sub-sampling.  For components
       that are sub-sampled in one direction, but not the other, visual
       weighting factors for the HL and LH subbands are naturally treated
       differently.
          We note that the subband weighting approach described above is
       intended to correspond to that implemented explicitly by all Kakadu
       compression demo-apps prior to version 8.0.4, but handles non-uniform
       chrominance sampling (e.g., 4:2:2 content) a little better.
          The `Ctype' attribute greatly simplifies the introduction of these
       visual weighting factors, while providing an extra twist.  If a high
       `Qfactor' (quality factor) value is specified, then these default visual
       weights are attenuated, dragging them towards 1.0 (i.e., equi-weighted
       subbands that maximize distortion-rate performance for the MSE
       distortion metric) as the `Qfactor' value approaches 100%; this
       behaviour can be customized via the `Qfparams' attribute.
   Qstep[:<TC>]={<float>}
       (ENCODER Meta-Attribute):  Base step size to be used in deriving
       irreversible quantization step sizes for every subband.  The base step
       parameter should be in the range 0 to 2.  If the `Qfactor' attribute is
       specified, it is usually desirable to leave `Qstep' unspecified, since
       the main role of `Qfactor' is to assign the `Qstep' value.  It may be
       useful, however, to specify `Qstep' for some components, so as to
       override the quantizer scaling factor automatically selected by the
       `Qfactor' algorithm for just those components.
           [If `Qfactor' and `Qstep' are both unspecified, the default value
           for `Qstep' is 1/2^P, where P is the sample precision for the
           relevant image component, truncated to the interval 8 <= P <= 12 --
           much finer `Qstep' values can be selected if required.]
   Qfix16[:<TC>]={ENUM<FREE,LIMIT>}
       (ENCODER Meta-Attribute):  If this attribute is present, the
       quantization step sizes that are otherwise configured in `Qabs_steps'
       (either directly or with the aid of `Qstep' and/or `Qweights') are
       optimized for 16-bit fixed-point processing.  Step sizes are adjusted
       (mostly downwards) so that the quantization and dequantization operators
       encountered in fixed-point processing should involve scaling only by
       powers of 2.  If the value of the attribute is `Qfix16_LIMIT', the
       quantization step sizes are additionally adjusted so as to prevent any
       subband from receiving more than 15 magnitude bits (including guard
       bits), ignoring the impact of any max-shift based ROI adjustments (see
       `Rshift').  If the value is `Qfix16_FREE', this additional adjustment is
       not made, allowing some (typically low frequency) subbands to receive
       very fine quantization, perhaps at the expense of a more expensive block
       coding opertion.  The first set of adjustments, leaving power of 2
       quantization operators, avoids the introduction of numerical rounding
       errors in 16-bit fixed-point implementations.  While step sizes
       generally need to be adjusted, there is no strong reason to believe that
       this should adversely affect the performance of irreversible compression
       when EBCOT's PCRD-opt algorithm is used for rate control (the default
       approach).  At very high bit-rates, the performance of irreversible
       compression is usually improved by specifying the `Qfix16' attribute. 
       Also, the difference between fixed-point and floating-point decoded
       versions of the same code-stream is reduced by adopting
       `Qfix16'-modified quantization parameters.  This attribute has no effect
       if processing is reversible (`Creversible' is true) or if `Qderived' is
       true.  If `Qfactor' is specified without being explicitly overridden by
       specification of a `Qstep' value, then use of the `Qfix16' attribute
       results in a warning message.
   Qweights[:<T>]={<float>},...
       (ENCODER Meta-Attribute):  Used only when subband quantization steps
       sizes are derived using `Qstep' and `Qderived' is false (no).  If this
       attribute is specified and the first parameter is > 0.0, the
       quantization step sizes that would otherwise be derived from `Qstep' for
       a subband b in image component c, are scaled first by 1/(G_c*W_b), where
       G_c is the square root of the energy gain factor associated with
       synthesis in the multi-component transform, if any, and W_b represents
       the product of all relevant weighting factors, supplied via `Cweight',
       `Clev_weights', `Cband_weights' and/or (indirectly) `Ctype'.
          The `G_c' values are not computed by Kakadu from the properties of
       the multi-component transform; instead, they are supplied as parameters
       to this attribute, and they must all be strictly positive.  If you have
       no multi-component transform at all, then the correct value to supply is
       1.0, since any missing values are obtained by replicating the last one;
       in the common case where `Cycc'=yes, the JPEG 2000 Part-1
       multi-component decorrelating transform is being used for the first 3
       components and there is no other multi-component transform, so the
       correct values to supply are 1.7321, 1.8051, 1.5734, 1.0; for more
       general Part-2 multi-component transforms, calculating the synthesis
       energy gains by hand can be complex, but don't worry.  Kakadu does
       calculate the correct gains and will check the values you supply via
       this attribute, if present, reporting any significant deviations through
       a suitable warning message.  The reason for insisting that you supply
       the gains explicitly with this attribute is that it is awkward to
       compute them within the parameter sub-system, and this is where the
       gains are required in order to derive irreversible quantization step
       sizes that meet the objectives of the `Qweights' attribute.
          Specifically, the objective of `Qweights' is to arrange for the
       irreversible quantization step sizes derived from `Qstep' to incorporate
       all synthesis gains (i.e., all sources of quantization noise expansion)
       and all supplementary visual weighting factors that are used by Kakadu's
       Post-Compression Rate-Distortion optimization (PCRD-opt) algorithm when
       generating content constrained by an overall compressed size (e.g., the
       "-rate" argument to most/all Kakadu compression demo-apps) or
       distortion-length slope (e.g., the "-slope" argument to most/all Kakadu
       compression demo-apps).  When this is done, the operational
       rate-distortion characteristic of a compression system controlled by a
       global `Qstep' value should be substantially identical to that of a
       compression system that uses the PCRD-opt algorithm to control image
       quality instead.  In the former case, the rate-distortion trade-off is
       dictated by choice of `Qstep', while in the latter case it is controlled
       by codestream length (rate) or slope constraints, and `Qstep' is largely
       arbitrary, except that it should be sufficiently small to achieve the
       desired operating point.  Each approach has its merits for different
       applications, but `Qstep' control is most interesting when driven
       indirectly by a JPEG 2000 quality factor, supplied via the `Qfactor'
       attribute.  The term "distortion" here means (visually) Weighted Mean
       Squared Error (WMSE), where the (visual) weights are determined from
       `Cweights', `Clev_weights', `Cband_weights' and/or `Ctype'.
           [This attribute is not defined by default, except in the case where
           `Qfactor' is used.  In that case, if you have not supplied
           `Qweights' explicitly, Kakadu currently sets `Qweights' either to
           1.0 or to the values mentioned above for the `Cycc'=yes case -- for
           Part-2 multi-component transforms, these auto-generated values will
           not generally be correct, resulting in the warning message mentioned
           above, with information about the correct values to use.]
   Qfactor[:<T>]={<float>}
       (ENCODER Meta-Attribute):  This attribute is primarily intended to
       provide quality-factor based control of JPEG 2000 encoding, with similar
       subjective properties to the quality factor that is widely used to
       control traditional JPEG encoding.  Legal quality factors are
       real-valued numbers greater than 0 and less than or equal to 100, with
       50 denoting a moderate quality and 85 or above generally considered to
       correspond to very high quality.  In Kakadu, the quality factor does two
       things: first, it determines a set of subband visual weighting factors
       that become overridable defaults for the `Cband_weights' attribute;
       second, it determines a `Qstep' base quantization step size parameter
       that is combined with all relevant quantization noise gains and visual
       weighting factors via the `Qweights' attribute, to obtain suitable
       quantization step sizes for every subband.  If `Qweights' is not
       explicitly provided, Kakadu will attempt to install suitable default
       values, but see the explanation under `Qweights' for more on this.
          To derive a `Qstep' value, the `Qfactor' parameter Q is first
       converted to a linear multiplier M by setting M=50/Q for Q <= 50 and
       M=2*(1-Q/100) for 50 <= Q <= 100.  In JPEG, M usually scales the example
       quantization tables published with the original standard. In JPEG 2000,
       M is used to derive the `Qstep' base quantization step size, which is
       then modified by visual weights.  Specifically, `Qstep' is set to
       (Fq*M*QW0 + eps0), if not specified explicitly, where the value of Fq
       ranges between Fq0 and Fq1, as Q goes from low to moderate qualities
       like 50, up to the maximum quality of 100.
          We recommend that you do not specify `Cband_weights' directly, in
       which case subband visual weighting factors are derived via the `Ctype'
       attribute, in a way that also varies as Q approaches 100, eventually
       reaching the uniform (i.e., unweighted) case that roughly minimizes the
       objective (MSE) distortion metric for a given compressed size, rather
       than subjective (visual) quality.
          Exactly how these transitions happen, along with the values of Fq0
       and Fq1, can be controlled via the `Qfparams' attribute, but the default
       values are Fq0=0.04 and Fq1=0.10, with the transition proceeding
       logarithmically with respect to M, between Q=65 and Q=97, beyond which
       subbands are unweighted.
          The value of the offset `eps0' in the exression (Fq*M*QW0+eps0) for
       `Qstep', is eps0 = 2^{-P0}/sqrt(2), where P0 is the first image
       component, or the first luminance component, if one is specified via
       `Ctype', adjusted, if necessary, to ensure that P0 >= 8.  QW0 is the
       `Qweights' parameter corresponding to this same component (the first
       one, or the first luminance component).  The inclusion of QW0 ensures
       that quality factor Q controls the quality of the luminance component in
       the same way that it controls the quality of a greyscale image,
       regardless of the way noise expands through any multi-component
       transform.  The inclusion of `eps0' ensures that when quality factor Q
       reaches its maximum value of 100, leaving M=0, the `Qstep' value becomes
       2^{-P0}/sqrt(2) which, in the absence of any visual weighting, results
       in an MSE quantization noise power which is about half the natural
       digitization noise power associated with representing continuous image
       intensities using P0-bit integers.
          NOTE 1: at least one of `Cband_weights' or `Ctype' must be available
       when `Qfactor' is used, but in many cases the compression application
       may provide `Ctype' explicitly.
          NOTE 2: if `Qstep' is already explicitly defined, the `Qfactor'
       attribute can still affect subband visual weighting factors, as
       described above, but it has no direct influence on the quantization step
       size.
          NOTE 3: in the usual case, where `Qstep' is not defined, `Qweights'
       must not be explicitly set to `no' and `Qderived' must not be set, since
       `Qfactor' requires the `Qweights' functionality for its `Qstep'
       assignment policy to be meaningful.
          NOTE 4: we point out that `Qfactor', like `Qstep', only establishes
       the finest level of quantization for any given subband, but Kakadu may
       apply further restrictions to the emitted codestream content during its
       post-compression rate-distortion optimization (PCRD-opt) phase, subject
       to a specified codestream size or distortion-length slope threshold, or
       more detailed constraints supplied via `Creslengths' or `Cagglengths',
       or perhaps due to an `SCP15_limb' limit on the precision of HT
       code-block sample magnitudes.
          NOTE 5: it is possible to specify different `Qfactor' values for
       indivdual tiles, but not for individual components.
   Qfparams[:<T>]={<float>,<float>,<float>,<float>}
       This attribute is relevant only in conjunction with `Qfactor'; it
       provides 4 real-valued parameters Fq0, Tq0, Fq1 and Tq1, in that order,
       which work with the `Qfactor' parameter Q to determine how subband
       visual weighting factors are derived from `Ctype', assuming that
       `Cband_weights' is not specified explicitly, and also to determine the
       scaling factor Fq, where an unspecified `Qstep' attribute is assigned
       the value (Fq*M + eps), as explained with the `Qfactor' attribute. 
       Specifically: a) for Q <= Tq0, Fq = Fq0; b) for Q >= Tq1, Fq = Fq1; and
       c) for Tq0 < Q < Tq1, Fq takes values that vary smoothly with Q, between
       Fq0 and Fq1 -- in fact, Fq is a linear function of log(M), where M is
       derived from Q in the manner described with `Qfactor'.  The parameters
       must satisfy 5 < Tq0 <= Tq1 < 100, while  are required to be strictly
       positive.
           [If `Qfactor' is specified, then the four parameters default to
           Fq0=0.04, Tq0=65.0, Fq1=0.10 and Tq1=97.0.]
   Cycc[:<T>]={<yes/no>}
       RGB to Luminance-Chrominance conversion?
           [Default is to convert images with 3 or more components, unless a
           Part 2 multi-component transform is defined -- `Mcomponents' > 0]
   Cmct[:<T>]={FLAGS<ARRAY|DWT>}
       This parameter should be 0 unless a Part 2 multi-component transform is
       being used, in which case it contains one or both of the `ARRAY' and
       `DWT' options -- if both options are present, they are separated by a
       `|'.  The `ARRAY' option will be present if and only if an array-based
       multi-component transform block is associated with the image, or the
       relevant tile (for tile-specific instances of the attribute).  The `DWT'
       option will be present if and only if a DWT-based multi-component
       transform block is associated with the image, or the relevant tile (for
       tile-specific instances of the COD marker segment).  Both flags will be
       present if both types of multi-component transform block are employed
       for the image or tile, as appropriate.  During codestream generation,
       the information in this parameter is generated automatically to conform
       with the information provided via the `Mstages' and `Mstage_xforms'
       attributes.  When reading an existing codestream, the information in
       this parameter should either be correct or 0.  In the latter case, the
       internal machinery interprets the codestream as one generated by
       versions of Kakadu prior to v6.0, wherein the transform coefficients for
       reversible matrix-based transforms were accidentally transposed -- the
       transposition error is corrected automatically in this case.
   Clayers[:<T>]={<int>}
       Number of quality layers. May not exceed 16384.
           [Default is 1]
   Cuse_sop[:<T>]={<yes/no>}
       Include SOP markers (i.e., resync markers)?
           [Default is no SOP markers]
   Cuse_eph[:<T>]={<yes/no>}
       Include EPH markers (marker end of each packet header)?
           [Default is no EPH markers]
   Corder[:<T>]={ENUM<LRCP,RLCP,RPCL,PCRL,CPRL>}
       Default progression order (may be overridden by Porder).  The four
       character identifiers have the following interpretation: L=layer;
       R=resolution; C=component; P=position. The first character in the
       identifier refers to the index which progresses most slowly, while the
       last refers to the index which progresses most quickly.
           [Default is LRCP]
   Calign_blk_last[:<T>]={<yes/no>,<yes/no>}
       If "yes", the code-block partition is aligned so that the last sample in
       each nominal block (ignoring the effect of boundaries) is aligned at a
       multiple of the block dimension (a power of 2).  Equivalently, the first
       sample in each nominal block lies at a location which is a multiple of
       the block dimension, plus 1. By default (i.e., "no"), the first sample
       of each block is aligned at a multiple of the block dimension. The
       alignment is specified separately for both dimensions, with the vertical
       dimension specified first.
   Clevels[:<TC>]={<int>}
       Number of wavelet decomposition levels, or stages.  May not exceed 32.
           [Default is 5]
   Cads[:<TC>]={<int>}
       Index of the ADS marker segment used to hold Arbitrary Downsampling
       Style information.  If ADS information is involved, the value of the
       `Cads' index must lie in the range 1 to 127.  A value of 0 means that no
       ADS marker segment is referenced.  You will not normally set this
       parameter yourself.  It is preferable to allow the internal machinery to
       find a suitable index.  In any event, the ADS information recorded in
       the `DOads' and `DSads' attributes will be generated automatically from
       information contained in `Cdecomp'.  During marker segment reading, the
       ADS information is used together with any DFS information (see `Cdfs')
       in order to reconstruct the `Cdecomp' attribute.
           [Best not to set this yourself.  An index is selected automatically
           if `Cdecomp' defines a non-trivial decomposition.]
   Cdfs[:<TC>]={<int>}
       Index of the DFS marker segment used to hold Downsampling Factor Style
       information.  If DFS information is involved, the value of the `Cdfs'
       index must be in the range 1 to 127.  A value of 0 means that no DFS
       marker segment is referenced.  This attribute is ignored outside of the
       main header (i.e., for non-negative tile indices).  You will not
       normally set this parameter yourself.  Rather, it is preferable to allow
       the internal machinery to find a suitable index for you.  In any event,
       the DFS instructions recorded in the `DSdfs' attribute will be generated
       automatically from information contained in `Cdecomp'.  During marker
       segment reading, the DFS instructions will be read, along with any ADS
       information (see `Cads') in order to reconstruct the `Cdecomp'
       attribute.
           [Best not to set this yourself.  An index is selected automatically
           if `Cdecomp' defines a non-trivial decomposition.]
   Cdecomp[:<TC>]={<custom int>},...
       Manages the information associated with the JPEG2000 Part-2 `ADS' and
       `DFS' marker segments, if any, as referenced by the `Cads' and `Cdfs'
       attributes.  If neither of these is present, the default value of 3 is
       used, which yields the conventional Mallat decomposition structure. 
       Each record describes the subband splitting processes for one entire DWT
       level, starting from the first (highest frequency) level.  The textual
       form of each record commences with a primary splitting code, which is
       one of the characters: `B' (split both ways a la Mallat); `H' (split
       only horizontally); `V' (split only vertically); or `-' (do not split at
       all -- degenerate case).  The first option produces three primary detail
       subbands, denoted HL, LH and HH.  The second and third options produce
       only one primary detail subband (HX or XH), while the last option
       produces no detail subbands at all.  The primary splitting code is
       followed by parentheses, containing 0, 1 or 3 colon-separated
       sub-strings, each of which describes the additional splitting operations
       to be applied to each primary detail subband.  Each sub-string consists
       of 1, 3 or 5 characters, drawn from `-' (meaning no-split), `H' (meaning
       a horizontal split), `V' (meaning a vertical split) and `B' (meaning a
       bi-directional split).  If the sub-string commences with `H' or `V', two
       additional characters may be provided to describe further splitting of
       the low- and high-pass subbands produced by the first split.  If the
       sub-string commences with `B', four additional characters may be
       provided to describe further splitting of the LL, HL, LH and HH subbands
       produced by the primary split.  Alternatively, the sub-string may
       consist only of the initial character, in which case no further
       splitting is involved.  Thus, "B" and "B----" are equivalent
       sub-strings, as are "H" and "H--".
          If insufficient parameters are supplied to accommodate the number of
       desired DWT levels, the final value is simply replicated.  Note,
       however, that the last value must conform to some specific rules, which
       derive from the way in which JPEG2000 Part-2 defines extrapolation for
       information found in the ADS and DFS marker segments.  In particular,
       the terminal parameter must have identical splitting descriptors for all
       primary detail subbands (remember there are 0, 1 or 3 of these). 
       Moreover, within each of these descriptors, all splitting codes (`-',
       `H', 'V' and 'B') must be identical.  The only exception to this occurs
       where all primary detail subbands are split only once, in which case all
       primary detail subbands must have identical sub-strings holding one of
       the patterns, "B----", "H--", "V--" or "-".  Thus, "B(-:-:-)",
       "H(BBBBB)", "B(HHH:HHH:HHH)", "V(H--)" and "B(V--:V--:V--)" are all
       legal terminal values, while "B(B:B:-)" and "V(VV-)" are not legal.
           [If `Cdecomp' is not specified, a value is determined from the ADS
           and/or DFS information referenced by `Cads' and `Cdfs'.  If there is
           no such information, the default `Cdecomp' value is "B(-,-,-)",
           which translates to the integer value, 3.  All Part-1 codestreams
           must use this Mallat decomposition style.]
   Creversible[:<TC>]={<yes/no>}
       Reversible compression?
           [Default is irreversible, if `Ckernels' and `Catk' are not used,
           except where this conflicts with a specific profile requirement such
           as that of a reversible BROADCAST or IMF profile.  Otherwise, the
           reversibility is derived from those values.]
   Ckernels[:<TC>]={ENUM<W9X7,W5X3,ATK>}
       Wavelet kernels to use.  The special value, `ATK' means that an ATK
       (Arbitrary Transform Kernel) marker segment is used to store the DWT
       kernel.  In this case, the `Catk' attribute must be non-zero.
           [Default is W5X3 if `Creversible' is true, W9X7 if `Creversible' is
           false, and ATK if `Catk' is non-zero.]
   Catk[:<TC>]={<int>}
       A value of 0 means that the DWT kernel is one of W5X3 or W9X7, as
       specified by the `Ckernels' attribute.  Otherwise, this attribute holds
       the index of the ATK marker segment which defines the transform kernel. 
       The index must lie in the range 2 to 255 and corresponding
       `Kreversible', `Krev_steps' or `Kirv_steps' attributes must exist, which
       have the same index (instance) value.  Thus, for example, if `Catk=3',
       you must also supply a value for `Kreversible:I3' and/or `Krev_steps:I3'
       or `Kirv_steps:I3', as appropriate.  This information allows the
       internal machinery to deduce whether the transform is reversible or not.
       The ATK information in these parameter attributes can also be
       tile-specific.  To construct an arbitrary transform kernel, you can
       either explicitly provide the transform attributes via `Kreversible',
       `Ksymmetric', `Kextension', `Ksteps' and `Kcoeffs', or you can use the
       convenient `Kkernels' meta-attribute to build the parameters for
       pre-defined transforms that might exist; for example, "Kkernels:I3=R2X2"
       configures the reversible Haar transform for use with "Catk=3".
           [Default is 0]
   Cuse_precincts[:<TC>]={<yes/no>}
       Explicitly specify whether or not precinct dimensions are supplied.
           [Default is "no" unless `Cprecincts' is used]
   Cprecincts[:<TC>]={<int>,<int>},...
       Precinct dimensions (must be powers of 2). Multiple records may be
       supplied, in which case the first record refers to the highest
       resolution level and subsequent records to lower resolution levels. The
       last specified record is used for any remaining lower resolution
       levels.Inside each record, vertical coordinates appear first.
   Cblk[:<TC>]={<int>,<int>}
       Nominal code-block dimensions (must be powers of 2, no less than 4 and
       no greater than 1024, whose product may not exceed 4096). Actual
       dimensions are subject to precinct, tile and image dimensions. Vertical
       coordinates appear first.
           [Default block dimensions are {64,64}]
   Cmodes[:<TC>]={FLAGS<BYPASS|RESET|RESTART|CAUSAL|ERTERM|SEGMARK|HT|HTMIX|BYP
   ASS_E1|BYPASS_E2>}
       Block coder mode switches.  By default, all mode switches are turned
       off, unless the `Scap' attribute contains the `Scap_P15' flag, in which
       case the default value is `HT', which activates the Part-15 HT block
       coding algorithm.  Always use the labels `BYPASS', `RESET', `RESTART',
       `CAUSAL', `ERTERM', `SEGMARK', `HT', `HTMIX', `BYPASS_E1' and
       `BYPASS_E2' to configure modes instead of their numeric codes, which are
       subject to change.  Note that `BYPASS_E1' and `BYPASS_E2' modes are
       specific to Part-2 codestreams that conform to IS15444-2/AMD4; these two
       mode flags are meaningless unless combined with `BYPASS', in which case
       the arithmetic coder is bypassed 2*`BYPASS_E2' + `BYPASS_E1' bit-planes
       earlier than it otherwise would be, in the MR and SP coding passes.
          If `HT' is present without `HTMIX', the HT block coding algorithm of
       JPEG2000 Part-15 (High Throughput JPEG 2000) is being used exclusively,
       and so all other mode flags besides `CAUSAL' are ignored and will not be
       recorded in codestream marker segments.
          The `HTMIX' flag is always accompanied by `HT' -- if necessary, the
       `HT' flag will automatically be introduced.  In this mode, each affected
       code-block may use either the HT block coding algorithm or the original
       J2K block coding algorithm from IS15444-1, but the `BYPASS',
       `BYPASS_E1', `BYPASS_E2' and `RESTART' flags are not allowed -- if
       supplied during content generation, they will be cleared automatically
       and not recorded in the codestream.
   Qguard[:<TC>]={<int>}
       Number of guard bits to prevent overflow in the magnitude bit-plane
       representation. Typical values are 1 or 2.
           [Default is 1]
   Qderived[:<TC>]={<yes/no>}
       Quantization steps derived from LL band parameters? If "yes", all
       quantization step sizes will be related to the LL subband's step sizes
       through appropriate powers of 2 and only the LL band step size will be
       written in code-stream markers. Otherwise, a separate step size will be
       recorded for every subband. You cannot use this option with reversible
       compression.
           [Default is not derived]
   Qabs_steps[:<TC>]={<float>},...
       Absolute quantization step sizes for each subband, expressed as a
       fraction of the nominal dynamic range for that subband. The nominal
       range is equal to 2^B (B is the image sample bit-depth) multiplied by
       the DC gain of each low-pass subband analysis filter and the AC gain of
       each high-pass subband analysis filter, involved in the construction of
       the relevant subband. The bands are described one by one, in the
       following sequence: LL_D, HL_D, LH_D, ..., HL_1, LH_1, HH_1.  Here, D
       denotes the number of DWT levels.  Also, note that the actual set of
       subbands for which values are provided depends upon the decomposition
       structure identified via `Cdecomp'.  A single step size must be supplied
       for every subband (there is no extrapolation), except in the event that
       `Qderived' is set to "yes" -- then, only one parameter is allowed,
       corresponding to the LL_D subband.
           [For compressors, the absolute step sizes are ignored if `Qstep' or
           `Qfactor' is used.]
   Qabs_ranges[:<TC>]={<int>},...
       Number of range bits used to code each subband during reversible
       compression.  Subbands appear in the sequence, LL_D, HL_D, LH_D, ...,
       HL_1, LH_1, HH_1, where D denotes the number of DWT levels.  Note that
       the actual set of subbands for which values are provided depends upon
       the decomposition structure, identified via `Cdecomp'.  The number of
       range bits for a reversibly compressed subband, plus the number of guard
       bits (see `Qguard'), is equal to 1 plus the number of magnitude
       bit-planes which are used for coding its samples.
           [For compressors, most users will accept the default policy, which
           sets the number of range bits to the smallest value which is
           guaranteed to avoid overflow or underflow in the bit-plane
           representation, assuming that the RCT (colour transform) is used. 
           If explicit values are supplied, they must be given for each and
           every subband.]
   Rshift[:<TC>]={<int>}
       Region of interest up-shift value.  All subband samples which are
       involved in the synthesis of any image sample which belongs to the
       foreground region of an ROI mask will be effectively shifted up (scaled
       by two the power of this shift value) prior to quantization.  The region
       geometry is specified independently and is not explicitly signalled
       through the code-stream; instead, this shift must be sufficiently large
       to enable the decoder to separate the foreground and background on the
       basis of the shifted sample amplitudes alone.  You will receive an
       appropriate error message if the shift value is too small.
           [Default is 0]
   Rlevels[:<TC>]={<int>}
       Number of initial (highest frequency) DWT levels through which to
       propagate geometric information concerning the foreground region for ROI
       processing.  Additional levels (i.e., lower frequency subbands) will be
       treated as belonging entirely to the foreground region.
           [Default is 4]
   Rweight[:<TC>]={<float>}
       Region of interest significance weight.  Although this attribute may be
       used together with `Rshift', it is common to use only one or the other. 
       All code-blocks whose samples contribute in any way to the
       reconstruction of the foreground region of an ROI mask will have their
       distortion metrics scaled by the square of the supplied weighting
       factor, for the purpose of rate allocation.  This renders such blocks
       more important and assigns to them relatively more bits, in a manner
       which is closely related to the effect of the `Clev_weights' and
       `Cband_weights' attributes on the importance of whole subbands.  Note
       that this region weighting strategy is most effective when working with
       large images and relatively small code-blocks (or precincts).
           [Default is 1, i.e., no extra weighting]
   Porder[:<T>]={<int>,<int>,<int>,<int>,<int>,ENUM<LRCP,RLCP,RPCL,PCRL,CPRL>},
   ...
       Progression order change information.  The attribute may be applied
       globally (main header), or in a tile-specific manner (tile-part header).
       In this latter case, multiple instances of the attribute may be supplied
       for any given tile, which will force the generation of multiple
       tile-parts for the tile (one for each instance of the `Porder'
       attribute).  As with all attributes, tile specific forms are specified
       by appending a suffix of the form ":T<tnum>" to the attribute name,
       where <tnum> stands for the tile number, starting from 0.  Each instance
       of the attribute may contain one or more progression records, each of
       which defines the order for a collection of packets. Each record
       contains 6 fields. The first two fields identify inclusive lower bounds
       for the resolution level and image component indices, respectively. The
       next three fields identify exclusive upper bounds for the quality layer,
       resolution level and image component indices, respectively. All indices
       are zero-based, with resolution level 0 corresponding to the LL_D
       subband. The final field in each record identifies the progression order
       to be applied within the indicated bounds. This order is applied only to
       those packets which have not already been sequenced by previous records
       or instances.
   CRGoffset={<float>,<float>},...
       Provides additional component registration offsets. The offsets add to
       those implied by the canvas coordinate system and should only be used
       when canvas coordinates (notably `Ssize', `Soffset' and `Ssampling')
       cannot be found, which adequately reflect the relative displacement of
       the components. Each record specifies offsets for one component, with
       the vertical offset appearing first. Offsets must be in the range 0
       (inclusive) to 1 (exclusive) and represent a fraction of the relevant
       component sub-sampling factor (see `Ssampling'). The last supplied
       record is repeated as needed to recover offsets for all components. 
   ORGtparts[:<T>]={FLAGS<R|L|C>}
       Controls the division of each tile's packets into tile-parts.  The
       attribute consists of one or more of the flags, `ORGtparts_R',
       `ORGtparts_L' and `ORGtpargs_C'.  If the `ORGtparts_R' flag is supplied,
       tile-parts will be introduced as necessary to ensure that each tile-part
       consists of packets from only one resolution level.  If `ORGtparts_L' is
       supplied, tile-parts are introduced as necessary to ensure that each
       tile-part consists of packets from only one quality layer.  Similarly,
       if `ORGtparts_C' is supplied, each tile-part will consist of packets
       from only one component.  Note that the cost of extra tile-part headers
       will not be taken into account during rate control, so that the
       code-stream may end up being a little larger than you expect.  By
       default, tile-part boundaries are introduced only as required by the
       presence of multiple `Porder' attribute specifications (see
       `poc_params') and/or incremental codestream flushing, which can produce
       tile-part boundaries due to interruption in the set of available J2K
       packets during a flush cycle; these interruptions can be bounded via the
       `ORGtpart_interrupts' attribute.
           [By default, tile-part bondaries are introduced only as required by
           incremental flushing or the presence of multiple "Porder" attribute
           specifications.]
   ORGgen_plt[:<T>]={<yes/no>}
       Requests the insertion of packet length information in the header of all
       tile-parts associated with tiles for which this attribute is turned on
       (has a value of "yes").  The PLT marker segments written into the
       relevant tile-part headers will hold the lengths of those packets which
       belong to the same tile-part.  Note that the cost of any PLT marker
       segments generated as a result of this attribute being enabled will not
       be taken into account during rate allocation.  This means that the
       resulting code-streams will generally be a little larger than one might
       expect; however, this is probably a reasonable policy, since the PLT
       marker segments may be removed without losing any information.  Also
       note that the `ORGplt_parts' attribute may be used to take control over
       the way in which PLT information is partitioned into distinct PLT marker
       segments.
   ORGplt_parts[:<T>]={FLAGS<R|L|C>}
       Controls the division of packet length information into PLT marker
       segments; this attribute has no impact unless `ORGgen_plt' is true.  The
       attribute consists of one or  more of the flags `R', `L' and `C',
       separated by the vertical bar character, `|'.  If the `R' flag is
       supplied, new PLT marker segments will be started as required to ensure
       that no PLT marker segment contains length information for packets that
       belong to different resolution levels.  Similarly, the `L' and `C' flags
       cause packet length information to be partitioned into distinct PLT
       marker segments at quality layer and codestream image component
       boundaries, respectively.
           [By default, packet length information is packed into the smallest
           possible collection of PLT marker segments.]
   ORGgen_tlm[:<T>]={<int>}
       Requests the insertion of TLM (tile-part-length) marker segments in the
       main header, to facilitate random access to the code-stream.  This
       attribute takes a single integer-valued parameter, which identifies the
       maximum number of tile-parts which will be written to the code-stream
       for each tile.  The reason for including this parameter is that space
       for the TLM information must be reserved ahead of time; once the entire
       code-stream has been written the generation machinery goes back and
       overwrites this reserved space with actual TLM data.  If the actual
       number of tile-parts which are generated is less than the value supplied
       here, empty tile-parts will be inserted into the code-stream so as to
       use up all of the reserved TLM space.  For this reason, you should try
       to estimate the maximum number of tile-parts you will need as accurately
       as possible, noting that the actual value may be hard to determine ahead
       of time if incremental flushing features are to be employed.  An error
       will be generated at run-time if the number of declared maximum number
       of tile-parts turns out to be insufficient.  Fortunately, you can bound
       the impact of incremental flushing on the number of extra tile-parts
       that may be introduced beyond the control of the coding parameters
       themselves by specifying a value for the `ORGtpart_interrupts'
       attribute.  You should note that the `ORGgen_tlm' attribute may be
       ignored if the `kdu_compressed_target' object, to which generated data
       is written, does not support repositioning functionality.
   ORGtlm_style[:<T>]={ENUM<implied,byte,short>,ENUM<short,long>}
       This attribute can be used to control the format used to record TLM
       (tile-part-length) marker segments; it is relevant only in conjunction
       with "ORGgen_tlm".  The standard defines 6 different formats for the TLM
       marker segment, some of which are more compact than others.  The main
       reason for providing this level of control is that some
       applications/profiles may expect a specific format to be used.  By
       default, each record in a TLM marker segment is written with 6 bytes, 2
       of which identify the tile number, while the remaining 4 give the length
       of the relevant tile-part.  This attribute takes two fields: the first
       field specifies the number of bytes to be used to record tile numbers
       (0, 1 or 2); the second field specifies the number of bytes to be used
       to record tile-part lengths (2 or 4).  The values provided here might
       not be checked ahead of time, which means that some combinations may be
       found to be illegal at some point during the compression process.  Also,
       the first field may be 0 (meaning "implied") only if tiles are written
       in order and have exactly one tile-part each.  This is usually the case
       if "ORGtparts" is not used, but incremental flushing of tiles which are
       generated in an unusual order may violate this assumption -- this sort
       of thing can happen if Kakadu's appearance transforms are used to
       compress imagery which is presented in a transposed or flipped order,
       for example.
   ORGtpart_interrupts[:<T>]={<int>}
       Can be used to bound the impact of incremental codestream flushing on
       the introduction of tile-parts into the generated codestream.  This
       attribute is irrelevant if you are not doing incremental flushing, or if
       you are flushing to a structured compressed data cache, rather than a
       sequential codestream.  Incremental flushing may result in some
       precincts of a tile being available before others so that a flush cycle
       needs to output some packets of the tile to a separate tile-part,
       leaving the rest to follow in a later tile-part.  These interruptions
       can be hard to predict, especially in multi-threaded implementations,
       which can result in the hard limit of 255 tile-parts per tile being
       exceeded or the number of tile-parts reserved by `ORGgen_tlm' for main
       header tile-part pointers being insufficient.  To avoid both
       difficulties, this attribute allows you to specify a bound on the
       maximum number of tile-part boundaries that can occur as a result of
       data interruptions created by incremental flushing.  You should factor
       this bound into the value you pass with any `ORGgen_tlm' parameter
       attribute.  If the bound is at risk of being exceeded, the incremental
       flushing of content for a tile is suspended until all precincts of the
       tile have been generated.  You should be aware that this may reduce the
       performance of incremental flushing, in which case you should consider
       enlarging the bound supplied via `ORGtpart_interrupts'.
           [Defaults to 200, which is large enough to accommodate most
           incremental flushing configurations and leaves enough remaining
           tile-parts to accommodate most `ORGtparts' configurations without
           violating the hard limit of 255 parts per tile.  However, if you are
           using `ORGgen_tlm' to generate tile-part pointer information, you
           really should choose a suitable small value for this parameter and
           add it to the minimum value that would be required by `ORGgen_tlm'
           in the absence of incremental flushing.]
   Mmatrix_size[:<TI>]={<int>}
       Identifies the number of matrix elements, if any, represented by this
       object.  The actual matrix coefficients are represented by the
       `Mmatrix_coeffs' attribute.  Matrices are used to describe reversible
       and irreversible inverse component decorrelation transforms.  This is
       done by referencing the current attribute's instance index from the
       second field in each record of the `Mstage_xforms' attribute used to
       describe a multi-component transformation stage.  Thus, for example,
       "Mstage_xforms:I1={MATRIX,1,4,0,0},{MATRIX,3,0,1,0}" declares that a
       given multi-component transform stage, having instance index 1, and two
       component collections, employs matrix transforms for both collections. 
       The first collection's matrix is described by `Mmatrix_size:I1' and
       `Mmatrix_coeffs:I1', while the second collection's matrix is described
       by `Mmatrix_size:I3' and `Mmatrix_coeffs:I3'.  To understand the last
       two fields in each record of the `Mstage_xforms' attribute, please refer
       to the separate description of that attribute.
   Mmatrix_coeffs[:<TI>]={<float>},...
       Coefficients of the matrix, if there is one, whose number of elements is
       given by `Mmatrix_size'.  The coefficients appear in row-major order
       (first row, then second row, etc.).  The height and width of the matrix
       are not recorded here, but matrices are not required to be square.  For
       reversible transforms, the matrix coefficients are required to be
       integers.
   Mvector_size[:<TI>]={<int>}
       Identifies the number of vector elements, if any, represented by this
       object.  The actual vector coefficients are represented by the
       `Mvector_coeffs' attribute.  Vectors are used to describe offsets to be
       applied to the component sample values after inverse transformation. 
       This is done by referencing the current attribute's instance index from
       the third field in each record of the `Mstage_xforms' attribute used to
       describe a multi-component transform stage.  Thus, for example,
       "Mstage_xforms:I1={MATRIX,1,4,0,0},{MATRIX,3,0,1,0}" declares that a
       given multi-component transform stage, having instance index 1, and two
       component collections, employs matrix transforms for both collections. 
       The first collection also involves offsets, described via
       `Mvector_size:I4' and `Mvector_coeffs:I4', while the second collection
       does not use offsets.  to understand the remaining fields in each record
       of the `Mstage_xforms' attribute, consult the separate description of
       that attribute.
   Mvector_coeffs[:<TI>]={<float>},...
       Coefficients of the vector, if there is one, whose number of elements is
       given by `Mvector_size'.  Unlike `Mmatrix_coeffs' and `Mtriang_coeffs',
       this attribute is extrapolated if insufficient parameters are supplied
       -- that is, the last supplied value is replicated as required in order
       to provide all `Mvector_size' vector elements.
   Mtriang_size[:<TI>]={<int>}
       Identifies the total number of sub-triangular matrix elements, if any,
       represented by this object.  A sub-triangular matrix is square, with no
       coefficients above the diagonal and at least one coefficient missing
       from the diagonal.  A strictly sub-triangular M x M matrix will have
       M*(M-1)/2 coefficients, all below the diagonal.  Matrices of this form
       are used to describe irreversible multicomponent dependency transforms. 
       Reversible dependency transforms, however, include all but the upper
       left diagonal entry, for a total of M*(M+1)/2-1 coefficients. 
       Dependency transforms are described by referencing the current
       attribute's instance index from the second field in each record of the
       `Mstage_xforms' attribute used to describe a multi-component transform
       stage.  Thus, for example, "Mstage_xforms:I1={DEP,5,0,0,0}" declares
       that a given multi-component transform stage, having instance index 1,
       and one component collection, employs a dependency transform, whose
       coefficients are counted by `Mtriang_size:I5' and found in
       `Mtriang_coeffs:I5'.
   Mtriang_coeffs[:<TI>]={<float>},...
       Coefficients of the sub-triangular matrix, if any, whose number of
       elements is represented by the `Mtriang_size' attribute.  The
       coefficients are arranged in row-major order.  Thus, for a dependency
       transform with M inputs and outputs, the first coefficient (first two
       for reversible transforms) comes from the second row of the matrix, the
       next two (three for reversible transforms) comes from the third row of
       the matrix, and so forth.  For reversible transforms, the coefficients
       must all have integer values.
   Mstage_inputs[:<TI>]={<int>,<int>},...
       This attribute is used to describe a list of input component indices
       which are used by all transform blocks in a single stage of the
       multi-component transform.  This list of component indices is a
       concatenation of the index ranges <A1>-<B1>, <A2>-<B2>, ..., where An <=
       Bn are the first and second fields in the n'th record of the
       `Mstage_inputs' attribute.   The list of input component indices may
       contain repeated values, but must cover all components produced by the
       previous stage (or all codestream component indices, if this is the
       first stage).  In particular, it must always include 0.  The first
       transform block operates on the first N1 components identified by this
       list; the second transform block operates on the next N2 components in
       this list; and so forth.
   Mstage_outputs[:<TI>]={<int>,<int>},...
       This attribute is used to describe a list of output component indices
       which are produced by this stage.  This list  of component indices is a
       concatenation of the index ranges <A1>-<B1>, <A2>-<B2>, ..., where An <=
       Bn are the first and second fields in the n'th record of the
       `Mstage_outputs' attribute.  The list of output component indices may
       not contain any repeated component indices, but it may contain "holes". 
       The transform stage is considered to generate components with indices
       from 0 to the largest index in the output list; any components in this
       range which are not listed (these are the holes) are taken to be
       identically equal to 0.  The first transform block in the stage
       processes the first N1 components in the list to produces the first M1
       components in the output list; the second transform block in the stage
       processes the next N1 components in the input list, producing the next
       M2 components in the output list; and so forth.
   Mstage_collections[:<TI>]={<int>,<int>},...
       This attribute provides the values Nc and Mc which appear in the
       descriptions of `Mstage_inputs' and `Mstage_outputs', for each transform
       block (equivalently, each component collection), c.  The
       `Mstage_collections' parameter attribute should contain one record for
       each transform.  Each record contains two strictly positive integers,
       identifying the number of input components Nk, and the number of output
       components, Mk, produced by the k'th transform.  No transform may
       consume or produce 0 components.  Between them, the various transform
       blocks must consume all components in the input list described by
       `Mstage_inputs' and produce all components in the output list described
       by `Mstage_outputs'.
   Mstage_xforms[:<TI>]={ENUM<DEP,MATRIX,DWT,MAT>,<int>,<int>,<int>,<int>},...
       This attribute provides one record for each transform block, which
       describes the type of transform to be implemented in that block and the
       parameters of the transform.  The first field identifies the transform
       as one of "dependency transform" (`DEP'), "decorrelation matrix
       transform" (`MATRIX'), or "discrete wavelet transform" (`DWT').  Do not
       use the `MAT' option; that option is provided to catch backward
       compatibility problems with Kakadu versions prior to v6.0, in which
       reversible decorrelation matrix transforms used a non-compliant
       organization for the coefficient values.  Kakadu will refuse to generate
       codestreams which use the `MAT' option, although it should be able to
       correctly recover and render codestreams generated with this option
       prior to v6.0.  It does this by recognizing the absence of the `Cmct'
       parameter attribute (another oversight prior to v6.0) as an indication
       that the non-compliant organization is being used.
          The 2'nd field of each record holds the instance index of the
       `Mtriang_coeffs' (for dependency transforms) or `Mmatrix_coeffs' (for
       decorrelation matrix transforms) attributes, which provide the actual
       transform coefficients, unless the transform is a DWT; in this last case
       the 2'nd field holds 0 for the 9/7 DWT, 1 for the 5/3 DWT, or the
       instance index (in the range 2 to 255) of an `ATK' marker segment whose
       `Kreversible', `Ksymmetric', `Kextension', `Ksteps' and `Kcoeffs'
       attributes describe the DWT kernel.  Apart from DWT transforms, a 0 for
       this field means that the transform block just passes its inputs through
       to its outputs (setting any extra output components equal to 0) and adds
       any offsets specified via the 3'rd field -- we refer to this as a "null"
       transform block.
          The 3'rd field of each record holds the instance index of the
       `Mvector_coeffs' attribute which describes any offsets to be applied
       after inverse transformation of the input components to the block.  A
       value of 0 for this field means that there is no offset; otherwise, the
       value must be in the range 1 to 255.
          For DWT transforms, the 4'th field in the record identifies the
       number of DWT levels to be used, in the range 0 to 32, while the final
       field holds the transform origin, which plays the same role as
       `Sorigin', but along the component axis.  For dependency and
       decorrelation transforms, the 4'th field must hold 0 if the transform is
       irreversible, or 1 if it is reversible, while the 5'th field must hold
       0.
   Mnum_stages[:<T>]={<int>}
       Identifies the number of stages in the multi-component transform to be
       applied to this tile, or (for main header attributes) as a default for
       tiles which do not specify the `Mnum_stages' attribute.  If this value
       is 0, the spatially transformed codestream components associated with
       the relevant tile are mapped directly to the output components specified
       via the global `Mcomponents', `Msigned' and `Mprecision' attributes.  If
       `Mcomponents' is larger than `Scomponents', some final components are
       automatically set to 0.  Where the number of stages is 0, codestream
       components which are identified as unsigned by the `Ssigned' attribute
       are first offset (at least nominally) by half their dynamic range, in
       the usual fashion.  If, on the other hand, `Mnum_stages' specifies a
       non-zero number of transform stages, component offsets must be provided
       by the multi-component transform stages themselves.
          It is worth noting that the above description applies to inverse
       transformation (synthesis) during decompression.  For a discussion of
       the conditions under which an appropriate forward transform can be
       performed during compression, see the description of the `Mcomponents'
       attribute.
           [This attribute defaults to 0 if a non-zero `Mcomponents' value
           exists, indicating the presence of a multi-component transform.]
   Mstages[:<T>]={<int>},...
       Provides `Mnum_stages' records, each of which holds the instance index
       (in the range 0 to 255) associated with the `Mstage_inputs',
       `Mstage_outputs', `Mstage_collections' and `Mstage_xforms' attributes
       which describe the corresponding stage in the inverse multi-component
       transform procedure.  The last stage is the one which produces the final
       decompressed components described by `Mcomponents', `Msigned' and
       `Mprecision'.
   NLType[:<TC>]={ENUM<NONE,GAMMA,LUT,SMAG,UMAG>}
       This attribute identifies the type of non-linear point transform to be
       applied.  In the case of NONE, no additional information is required. 
       The same is true for SMAG and UMAG.  The SMAG and UMAG options are
       intended for use in the compression of floating point data (including
       half floats) that have been cast to integers (bits have been
       re-interpreted as integers without any numerical processing).  This
       allows efficient compression of high dynamic range floating point data. 
       SMAG and UMAG can be used with any precision, but 16 would be common for
       the compression of half-floats.  The SMAG option is allowed only if the
       input and output precisions identified by `Sprecision'/`Mprecision' and
       `Nprecision' are identical and the `Ssigned'/`Msigned' and `Nsigned'
       attributes are both true; in this case, -ve values y are mapped to z =
       -2^{B-1} - y - 1, where B is the component bit-depth.  The UMAG option
       has the same constraints, but `Ssigned'/`Msigned' and `Nsigned'
       attributes must both be false; this means that true negative samples
       should never occur, so no transformation processing strictly needs to be
       performed, but numerical processing machinery needs to be especially
       careful not to allow the appearance of negative values that might
       otherwise appear as a result of quantization and numerical inaccuracies.
       For the other two types, GAMMA and LUT, the description is not complete
       without additional information supplied via `NLTgamma' or `NLTlut' and
       `NLTdata' attributes, respectively.  During codestream generation, these
       auxiliary attributes can be derived from `NLTmake', which provides
       simpler methods for specifying useful non-linear transforms.  Moreover,
       the `NLType' value itself can usually be automatically filled in based
       on the presence of any of the NLT auxiliary attributes.
   NLTgamma[:<TC>]={<float>,<float>,<float>,<float>,<float>}
       This attribute provides the 5 r+ve real-valued parameters that define a
       gamma-based non-linear point transformation.  The parameters are
       identified as E (exponent), S (toe slope), T (toe threshold), A and B
       (continuity parameters).  In a well-defined gamma expression, these 5
       parameters are not all independent, but they are separately recorded in
       the NLT marker segment.  The transform from the decoded output z of the
       NLT back to its input y is perhaps easiest to describe as y=S*z if
       |z|<=T/S, else y=sign(z) * (A*z^E - B).  In this description, both y and
       z are considered normalized so that the maximum nominal absolute value
       for both z and y is 1.0.  Actual values are stretched to fill the true
       nominal range.  The first obvious constraint that should be satisfied by
       a good gamma mapping is that A - B should be 1.0.  A second obvious
       constraint is that A*(T/S)^E should equal B+T -- this ensures continuity
       of the mapping.  There is one other condition that is satisfied by most
       gamma mappings; namely the condition that the mapping exhibit a
       continuous first derivative.  It can be seen that this requires S =
       A*E*T^{E-1}.  Note, however, that we do not enforce any of these
       conditions, since there might be some reason to intentionally use
       non-linear point transforms that do not satisfy them.  Instead, the
       `NLTmake' attribute provides a simple way to specify gamma functions
       that do satisfy all the conditions.  We conclude by noting that typical
       gamma functions involve E < 1 and T, B << 1, but all parameters are
       permitted to take values in the half-open interval [0,256).
   NLTlut[:<TC>]={<float>,<float>,<int>,<int>}
       This attribute serves to dimension the lookup table associated with a
       non-linear point transform having `NLType' = LUT.  The attribute takes a
       single record with four parameters.  The first two parameters are
       real-valued quantities Dmin and Dmax, while the last two parameters are
       integers N and P, respectively.  Here N >= 2 is the number of entries in
       the lookup table; P >= 1 is the number of bits used to represent the
       parameter values, meaning that they will be quantized to multiples of 1
       / (2^P - 1); 0 <= Dmin < Dmax <= 1.0 are the domain bounds, over which
       the entries to the lookup table are spaced uniformly.  These parameters
       describe the production of a decoded output value z, from its input
       value y, where y is the value produced at the output of the
       multi-component transform (or just the decoded codestream component, if
       there is no MCT) during decompression.  y values are first normalized to
       the interval [0,1] by level-shifting signed values and then scaling the
       values by 1 / (2^B-1), where B is the precision of the original y
       values.  y values are clipped to the range [Dmin,Dmax], after which an
       LUT index k is formed from k=floor(N*(y-Dmin)/(Dmax-Dmin)).   Then z is
       formed by starting with the interpolated value
       t_k+(N*(y-Dmin)/(Dmax-Dmin)-k)*(t_{k+1}-t_k), scaling it by (2^C-1),
       where C is the decoded output precision from `Nprecision' and finally
       level shifting it if `Nsigned' is true.  Here, the t_k values come from
       the separate `NLTdata' attribute.  Rather than specifying `NLTlut' and
       `NLTdata' attributes explicitly, it is usually much more convenient to
       generate them automatically via `NLTmake' instructions.
   NLTdata[:<TC>]={<float>},...
       This attribute provides the N values of the lookup table, where N is the
       number of lookup table entries supplied via the `NLTlut' attribute.  All
       of the real-valued parameters here must lie in the range 0.0 to 1.0,
       since the lookup table is expressed in a normalized domain, relative to
       the total dynamic range of the output values, being from 0 to 2^C-1,
       where C is the precision of the decoded values ultimately produced by
       the non-linear point transform, as identified via the `Nprecision'
       attribute.
   NLTmake[:<TC>]={ENUM<GAMMA,IGAMMA,LOG,ILOG>,<float>,<float>,<int>},...
       This attribute provides a convenient way to construct a variety of
       useful non-linear point transforms, as an alternative to directly
       specifying `NLTgamma' and `NLTlut'/`NLTdata' parameters. Each record in
       the multi-record attribute describes a single gamma or log-like point
       transform or its inverse.  The complete transform from the linear output
       samples y produced by wavelet synthesis (and optionally multi-component
       transformation) to the non-linear transform output samples z produced by
       a decompressor, is formed by concatenating the transforms described by
       each successive record supplied here, in sequence.  Each record
       commences with a transform type instruction that is one of GAMMA,
       IGAMMA, LOG or ILOG, followed by two real-valued parameters P1 and P2,
       and finally an integer number of points N for LUT approximations of the
       operator.  For GAMMA transforms, P1 is the reciprocal exponent 1/E and
       P2 is the offset parameter B from the 5 parameters defined in connection
       with `NLTgamma'; the other 3 parameters are obtained by enforcing
       continuity constraints.  This is arguably the most natural way of
       specifying gamma functions; the sRGB gamma function, for example, takes
       parameters 2.4 and 0.055.  The IGAMMA instruction builds the inverse of
       the gamma transform that would result from the same parameters.  This
       means that a cascade of two records specifying GAMMA and then IGAMMA but
       using the same P1 and P2 parameters would result in the identity
       transform.  LOG and ILOG have the same inverse relationship, so we need
       only explain the LOG form.    The LOG option describes a log-like
       transformation from original image samples z to transformed samples y
       that are subjected to linear transformation and coding during
       compression.  The transformation that occurs during decompression, as
       described by the generated lookup table, is that exponential (i.e., the
       reverse transform).  The forward log transform z in [0,1] to y in [0,1]
       according to y = A*(z/B) if z <= B, else y = A*(1+log(z/B)), where P1
       holds the B parameter (extent of the linear part of the mapping) and A =
       1 / (1-log(B)).  The parameter P2 is not used for LOG and ILOG forms.   
       Both LOG/ILOG and GAMMA/IGAMMA functions build transforms that work as
       expected on both signed and unsigned data, processing positive values in
       the manner described above, and processing negative values in an
       anti-symmetric manner.  As mentioned, the last parameter in each record
       holds the number of entries N used for lookup table approximations of
       the transform.  Lookup tables are required for anything other than a
       single record of type GAMMA, except perhaps with degenerate parameter
       values.  Where there are multiple records, the largest specified N value
       is the one that is used.
   Kkernels[:<TI>]={ENUM<I1X1,R1X1,I2X2,R2X2,I5X3>}
       This attribute is provided as a convenient way to generate and retrieve
       common ATK (arbitrary transform kernel) specifications based on
       pre-defined templates.  The set of pre-defined templates may grow in the
       future, but is currently limited to the following options:
       `Kkernels_R1X1' and `Kkernels_I1X1' are reversible and irreversible
       versions of the "lazy wavelet", meaning no transform at all;
       `Kkernels_I2X2' means the irreversible Haar transform; `Kkernels_R2X2'
       means the reversible Haar transform; and `Kkernels_I5X3' means the
       irreversible LeGall 5/3 transform, which is the irreversible version of
       the default Part-1 reversible 5/3 transform.  The `Kkernels' attribute
       itself is not recorded in the codestream, but is used to configure
       `Kreversible', `Ksymmetric', `Kextension', `Ksteps' and `Kcoeffs'
       attributes associated with the same parameter instance (the ":I" suffix,
       as in "Kkernels:I2=I5X3").  Additionally, the `Kkernels' attribute is
       automatically set based on recognized combinations of the `Kreversible',
       `Ksymmetric', `Kextension', `Ksteps' and `Kcoeffs' attributes, both upon
       marker segment parsing and during codestream generation, so that
       recognized ATK transforms are always flagged via the appropriate
       `Kkernels' value, allowing this to be used internally to accelerate
       configuration and computation of the wavelet transform machinery, when a
       recognized kernel is being employed.  The lazy wavelets (R1X1 and I1X1)
       pass image samples directly through to the subbands (after
       de-interleaving) to be either coded directly (reversible) or quantized
       and then coded (irreversible).  These can be useful for experimental
       applications, where a transform of interest is performed by a separate
       application and the interleaved subbands are supplied directly to Kakadu
       for compression, inverting the process during decompression.
   Kreversible[:<TI>]={<yes/no>}
       This attribute determines how the `Ksteps' and `Kcoeffs' attributes
       should be treated.  In the end, this parameter attribute must agree with
       the value of the `Creversible' attribute, for any tile-component which
       uses this transformation kernel.  However this consistency may be
       created by specifying `Kreversible' and leaving `Creversible'
       unspecified, so that an appropriate default value will be selected.
           [A default value cannot be created automatically, so you must
           explicitly specify a value if you want ATK information to become
           available for any particular instance index in the main header or a
           tile header.]
   Ksymmetric[:<TI>]={<yes/no>}
       If true, the transform kernel belongs to the whole-sample symmetric
       class, which is treated specially by JPEG2000 Part-2.  The translated
       impulse responses of these kernels are all symmetric about 0 -- see the
       Taubman & Marcellin book, Chapter 6, for a definition of translated
       impulse responses.  Equivalently, all lifting steps involve even-length
       symmetric lifting coefficients, Cs[n], where the coefficients associated
       with steps s=0, 2, 4, ... are symmetric about n = 1/2 and the
       coefficients associated with steps s=1, 3, 5, ... are symmetric about n
       = -1/2.
           [If you do not explicitly specify this attribute, it will be
           determined automatically from the lifting coefficient values
           supplied via `Krev_coeffs' or `Kirv_coeffs', as appropriate.]
   Kextension[:<TI>]={ENUM<CON,SYM>}
       Identifies the boundary extension method to be applied in each lifting
       step.  If `CON', boundary samples are simply replicated.  The other
       possible value, `SYM', means that boundary samples are symmetrically
       extended.  The centre of symmetry in this case is the boundary sample
       location within an interleaved representation in which low-pass samples
       occupy the even indexed locations and high-pass samples occupy the odd
       indexed locations.  The `SYM' method must be used if `Ksymmetric' is
       true.  Conversely, for filters which do not have the whole-sample
       symmetric property, you are strongly recommended to use the `CON'
       extension method.
           [Defaults to `SYM' if the filters are whole-sample symmetric and
           `CON' otherwise.]
   Ksteps[:<TI>]={<int>,<int>,<int>,<int>},...
       Array with one entry for each lifting step.  The first entry corrsponds
       to lifting step s=0, which updates odd indexed samples, based on even
       indexed samples; the second entry corresponds to lifting step s=1, which
       updates even indexed samples, based on odd indexed samples; and so
       forth.  The first field in each record holds the length, Ls, of the
       coefficient array Cs[n], for the relevant step s.  The second field is
       the location of the first entry, Ns, where Cs[n] is defined for n=Ns to
       Ns+Ls-1.  The value of Ns is typically negative, but need not be.  For
       symmetric kernels, Ls must be even and Ns must satisfy
       Ns=-floor((Ls+p-1)/2), where p is the lifting step parity (0 if s is
       even, 1 if s is odd).  The third and fourth fields must both be 0 if
       `Kreversible' is false.  For reversible transform kernels, however, the
       third field holds the downshift value, Ds, while the fourth field holds
       the rounding offset, Rs, to be added immediately prior to downshifting.
   Kcoeffs[:<TI>]={<float>},...
       Holds the lifting coefficients, Cs[n].  The first L0 records describe
       the coefficients of the first lifting step.  These are followed by the
       L1 coefficients of the second lifting step, and so forth.  The Ls values
       are identified by the first field in each `Ksteps' record.  Lifting step
       s may be described by X_s[2k+1-p] += TRUNC(sum_{Ns<=n<Ns+Ls}
       Cs[n]*X_{s-1}[2k+p+2n]).  In the case of an irreversible transform, the
       TRUNC operator does nothing and all arithmetic is performed (at least
       notionally) in floating point.  For reversible transforms, TRUNC(a) =
       floor(a + Rs*2^{-Ds}) and Cs[n] is guaranteed to be an integer multiple
       of 2^{-Ds}.
   DSdfs[:<I>]={ENUM<X,H,V,B>},...
       Describes the primary subband decomposition type associated with each
       DWT level, starting from the highest resolution (1'st level).  The value
       may be one of `B' (split in both directions), `H' (split horizontally),
       `V' (split vertically) or `X' (don't split at all).  The last case is
       degenerate, since it means that the DWT level in question produces no
       detail subbands whatsoever, simply passing its input image through to
       the next DWT level.  However, this can be useful in some circumstances. 
       The primary subband decomposition determines the downsampling factors
       between each successive resolution level.  If there are more DWT levels
       than `DSdfs' values, the last available value is replicated, as
       required.
           [You would not normally set values for this parameter attribute
           yourself.]
   Ddecomp[:<TI>]={<custom int>},...
       This attribute is ultimately set so as to hold the same information as
       the `Cdecomp' attribute of the COD/COC marker segment whose `Cads' holds
       our instance index.  Thus, for example, if `Cads'=3 then `Cdecomp' must
       be identical to `Ddecomp:I3'.  This identification is created by the
       internal machinery, however.  You should not explicitly set `Ddecomp'
       values yourself.
   DOads[:<TI>]={<int>},...
       Number of sub-levels in each successive DWT level, starting from the
       highest level.  Accesses to non-existent values are supported by
       repeating the last available value.  All entries must lie in the range 1
       to 3.  For the meaning of sub-levels in JPEG2000 Part-2, the reader is
       referred to Annex F of IS 15444-2.
           [You would not normally set values for this parameter attribute
           yourself.]
   DSads[:<TI>]={ENUM<X,H,V,B>},...
       Array of splitting instructions, whose interpretation generally depends
       upon the way in which ADS and DFS tables are jointly referenced from
       COD/COC marker segments, as identified by the `Cads' and `Cdfs'
       attributes.  Each splitting instruction must take one of the values: 3
       (split horizontally and vertically); 2 (split vertically); 1 (split
       horizontally); or 0 (do not split).  The last value is repeated as
       necessary, if accesses are made beyond the end of the array.  For the
       meaning of these splitting instructions, the reader is referred to Annex
       F of IS 15444-2.
           [You would not normally set values for this parameter attribute
           yourself.]
   -num_threads <#default threads>[,<#domain threads>[T|C]...]
       Use this argument to gain explicit control over multi-threaded or
       single-threaded processing configurations.  The special value of 0 may
       be used to specify that you want to use the conventional single-threaded
       processing machinery -- i.e., you don't want to create or use a
       threading environment.  Otherwise, you must supply a positive integer
       for the first argument, identifying the number of threads (including the
       main application thread) that have no preference as to where they do
       work, and you have the option also to specify the number of additional
       threads that should be assigned a preference to doing sample data
       transform processing (`T' suffix) or block coding operations (`C'
       suffix).  It is worth noting that "-num_threads 1" and "-num_threads 0"
       both result in single-threaded processing, although the former creates
       an explicit threading environment and uses it to schedule the processing
       steps, even if there is only one actual thread of execution.
          For effective use of parallel processing resources, you should
       consider creating at least one thread for each CPU; you should also
       consider using the `-double_buffering' option to minimize the amount of
       time threads might potentially sit idle.  Assigning work domain
       preferences to threads is an option that could be interesting to play
       around with, since this might lead to better utilization of processor
       caches.
          If the `-num_threads' argument is not supplied explicitly, the
       default behaviour is to create a threading environment only if the
       system offers multiple CPU's (or virtual CPU's), with one thread per
       CPU.  However, this default behaviour depends upon knowledge of the
       number of CPU's which are available -- something which cannot always be
       accurately determined through system calls.  The default value might
       also not yield the best possible throughput.
   -double_buffering <stripe height>
       This option is intended to be used in conjunction with `-num_threads'. 
       From Kakadu version 7, double buffering is activated by default in
       multi-threaded processing environments, but you can disable it by
       supplying 0 to this argument.
          Without double buffering, DWT operations are all performed by the
       single thread which "owns" the multi-threaded processing group.  For a
       small number of processors, this may be acceptable, or even optimal,
       since the DWT is generally quite a bit less CPU intensive than block
       encoding (which is always spread across multiple threads,  if available)
       and synchronous single-threaded DWT operations may improve memory access
       locality.  However, even for a small number of threads, the amount of
       thread idle time can be reduced by activating the `-double_buffering'
       option.  In this case, a certain number of image rows in each image
       component are actually double buffered, so that one set can be processed
       by colour transformation and sample reading operations, while the other
       set is processed by the DWT analysis engines, which themselves drive the
       block coding engines.  The number of rows in each component which are to
       be double buffered is known as the "stripe height", supplied as a
       parameter to this argument.  The stripe height can be as small as 1, but
       this may add quite a bit of thread context switching overhead.  For this
       reason, a stripe height in the range 8 to 64 is recommended.
          The default policy for multi-threaded environments is to pass the
       special value of -1 to `kdu_multi_analysis' so that a good value will be
       selected automatically.
   -split <preferred frag width>,<max frag depth>,<max fragments>
       From Kakadu version 7.11, the spatial transformation (DWT) process for
       any tile-component (image plane of a tile) can be split into multiple
       fragments that are processed simultaneously in separate threads.  This
       improves thread concurrency and can improve throughput on platforms with
       a large number of CPU cores; on smaller machines, however, it adds
       unnecessary overhead and so the feature is not enabled by default. 
       Splitting is only relevant for multi-threaded processing with double
       buffering (see the `-double_buffering' argument).  Note that splitting
       is not currently compatible with region-of-interest encoding.
          The <preferred frag width> parameter guides the selection of the
       width of each fragment into which a tile-component's processing is split
       (e.g. 4096).  The <max frag depth> parameter forces split processing
       pipelines to be fused below a certain depth in the spatial decomposition
       hierarchy, which usually happens automatically to avoid splitting up
       code-blocks of subbands, but can be further customized here (e.g. 4). 
       The last parameter allows you to constrain the number of processing
       fragments in each tile-component; you can explore the best value to use
       for a given number of processing threads or CPU cores (e.g. #cores /
       #components).
   -progress <interval>
       This option is useful when processing massive input images; it allows
       you to receive feedback each time a vertical row of tiles has been
       processed, but potentially more frequently, depending upon the
       <interval> parameter.  The application also provides feedback each time
       codestream flushing is initiated (paricularly useful in conjunction with
       `-flush_period').  The <interval> parameter indicates the maximum number
       of lines that can be pushed into the compression machinery before some
       progress is provided -- if this value is smaller than the tile height,
       you will receive periodic information about the percentage of the
       vertical row of tiles which has been processed.
   -cpu <coder-iterations>
       Times end-to-end execution and, optionally, the block encoding
       operation, reporting throughput statistics.  If `coder-iterations' is 0,
       the block coder will not be timed, leading to the most accurate
       end-to-end system execution times.  Otherwise, `coder-iterations' must
       be a positive integer -- larger values will result in more accurate
       estimates of the block encoder processing time, but degrade the accuracy
       of end-to-end system execution time estimates.  Note that end-to-end
       times include the impact of image file reading, which can be
       considerable.  Note also that timing information may not be at all
       reliable unless `-num_threads' is 1.  Since the default value for the
       `-num_threads' argument may be greater than 1, you should explicitly set
       the number of threads to 1 before collecting timing information.
   -mem -- Report memory usage.
   -mem_limit [<max kB>]
       Without any parameter, this argument causes memory information to be
       printed, as deduced via a `kdu_membroker' interface.  The reported value
       may be quite a bit larger than the actual amount of memory allocated,
       since it represents the cumulative memory allocation permission that was
       sought by almost all parts of the Kakadu system; many allocation centres
       request permission to allocate somewhat more memory than they need, so
       as to minimize the frequency of requests.
          The optional parameter allows you to hard limit the memory allocation
       permissions globally.  The limit is supplied in kB (i.e. multiples of
       1024 bytes).  You may find that processing is successful even if this
       limit is somewhat smaller than the value printed with "-mem_limit" is
       specified without a limit, because granting less memory allocation
       permission to an internal module does not necessarily prevent it from
       meeting its obligations.  However, when the limit is reduced
       substantially, an appropriate error message can be expected.  This
       provides a way to test robustness to memory allocation failures, but
       also demonstrates Kakadu's ability to work within a complex and
       potentially fragile system as a good citizen.
   -s <switch file>
       Switch to reading arguments from a file.  In the file, argument strings
       are separated by whitespace characters, including spaces, tabs and
       new-line characters.  Comments may be included by introducing a `#' or a
       `%' character, either of which causes the remainder of the line to be
       discarded.  Any number of "-s" argument switch commands may be included
       on the command line.
   -record <file>
       Record code-stream parameters in a file, using the same format which is
       accepted when specifying the parameters on the command line.
   -quiet -- suppress informative messages.
   -version -- print core system version I was compiled against.
   -v -- abbreviation of `-version'
   -usage -- print a comprehensive usage statement.
   -u -- print a brief usage statement."
   
Notes:
       Arguments which commence with an upper case letter (rather than a dash)
   are used to set up code-stream parameter attributes. These arguments have
   the general form:  <arg name>={fld1,fld2,...},{fld1,fld2,...},..., where
   curly braces enclose records and each record is composed of fields.  The
   type and acceptable values for the fields are identified in the usage
   statements, along with whether or not multiple records are allowed.  In the
   special case where only one field is defined per record, the curly braces
   may be omitted. In no event may any spaces appear inside an attribute
   argument.
       Most of the code-stream parameter attributes take an optional
   tile-component modifier, consisting of a colon, followed by a tile
   specifier, a component specifier, or both.  The tile specifier consists of
   the letter `T', followed immediately be the tile index (tiles are numbered
   in raster order, starting from 0).  Similarly, the component specifier
   consists of the letter `C', followed immediately by the component index
   (starting from 0). These modifiers may be used to specify parameter changes
   in specific tiles, components, or tile-components.
       If you do not remember the exact form or description of one of the
   code-stream attribute arguments, simply give the attribute name on the
   command-line and the program will exit with a detailed description of the
   attribute.
       If SIZ parameters are to be supplied explicitly on the command line, be
   aware that these may be affected by simultaneous specification of geometric
   transformations.  If uncertain of the behaviour, use `-record' to determine
   the final compressed code-stream parameters which were used.
       If you are compressing a 3 component image using the reversible or
   irreversible colour transform (this is the default), the program will
   automatically introduce a reasonable set of visual weighting factors, unless
   you use the "Clev_weights" or "Cband_weights" options yourself.  This does
   not happen automatically in the case of single component images, which are
   optimized purely for MSE by default.  To see whether weighting factors were
   used, you may like to use the `-record' option.
   
Understanding Multi-Component Transforms:
      Kakadu supports JPEG2000 Part 2 multi-component transforms.  These
   features are used if you define the `Mcomponents' attribute to be anything
   other than 0.  In this case, `Mcomponents' denotes the number of
   multi-component transformed output components produced during decompression,
   with `Mprecision' and `Msigned' identifying the precision and
   signed/unsigned attributes of these components.  These parameters will be
   derived from the source files (non-raw files), or else they will be used to
   figure out the source file format (raw files).  When working with
   multi-component transforms, the term "codestream components" refers to the
   set of components which are subjected to spatial wavelet transformation,
   quantization and coding.  These are the components which are supplied to the
   input of the multi-component transform during decompression.  The number of
   codestream components is given by the `Scomponents' attribute, while their
   precision and signed/unsigned properties are given by `Sprecision' and
   `Ssigned'.  You should set these parameter attributes to suitable values
   yourself.  If you do not explicitly supply a value for the `Scomponents'
   attribute, it will default to the number of source components (image planes)
   found in the set of supplied input files.  The value of `Mcomponents' may
   also be larger than the number of source components found in the supplied
   input files.  In this case, the source files provide the initial set of
   image components which will be recovered during decompression.  This subset
   must be large enough to allow the internal machinery to invert the
   multi-component transform network, so as to recover a full set of codestream
   image components.  If not, you will receive a descriptive error message
   explaining what is lacking.
      As an example, suppose the codestream image components correspond to the
   first N <= M principle components of an original set of M image components
   -- obtained by applying the KLT to, say, a hyperspectral data set.  To
   compress the image, you would probably want to supply all M original image
   planes.  However, you could supply as few as the first N original image
   planes.  Here, M is the value of `Mcomponents' and N is the value of
   `Scomponents'.
      If there is no multi-component transform, `Scomponents' is the number of
   output and codestream components; it will be set to the number of source
   components found in the set of supplied input files.  `Sprecision' and
   `Ssigned' hold the bit-depth and signed/unsigned attributes of the image
   components.
      From KDU-7.8, the `Ncomponents', `Nprecision' and `Nsigned' attributes
   provide means for defining the number, precision and signed/unsigned
   properties of the output image components (equivalently, the original input
   components to the compressor), in a manner that does not depend on whether
   or not there is a multi-component transform.  This mechanism also allows for
   the possibility that non-linear point transforms might appear between the
   original image samples and the multi-component output components or
   codestream components, changing the precision and/or signed/unsigned
   attributes yet again.  Where raw input files are used, without any precision
   information of their own, you should explicitly supply `Nprecision' and
   `Nsigned' values, allowing `Sprecision' and `Signed' and perhaps
   `Mprecision' and `Msigned' values to be derived automatically, unless you
   need to override them.  For non-raw input image formats, allow the internal
   machinery to set `Nprecision' and `Nsigned' attributes for you and override
   `Sprecision'/`Ssigned' or `Mprecision'/`Msigned' only if required by a
   non-linear point transform or multi-component transform you are interested
   in.
      It is worth noting that the dimensions of the N=`Scomponents' codestream
   image components are assumed to be identical to those of the N source image
   components contained in the set of supplied input files.  This assumption is
   imposed for simplicity in this demonstration application; it is not required
   by the Kakadu core system.
   
